# -*- coding: utf-8 -*-
"""Predictive_Analytics_MLT_Dicoding_Optimize_Moonchild.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1b1QH-h-UHQ608d-UamQotYBWGPQFuMfi

# Import Libraries
"""

import os
import math
import datetime
import traceback
import numpy as np
import pandas as pd
import seaborn as sns
import tensorflow as tf
import statsmodels.api as sm
import matplotlib.pyplot as plt

from scipy import stats
from scipy.special import boxcox1p
from matplotlib.dates import YearLocator
from statsmodels.tsa.stattools import adfuller, kpss
from sklearn.metrics import mean_absolute_error, mean_squared_error
from sklearn.model_selection import train_test_split
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Input, LSTM, Bidirectional, Dense, Dropout

"""#Exploratory Data Analysis (Data Cleansing)

##Load Datasets
"""

from google.colab import drive
drive.mount('/content/drive')

ispuRaw = pd.DataFrame()

for dataset in sorted(os.listdir('/content/drive/MyDrive/datasets/aqi_jakarta/akumulatif')):
  temp = pd.read_csv(f'/content/drive/MyDrive/datasets/aqi_jakarta/akumulatif/{dataset}')
  ispuRaw = pd.concat([ispuRaw, temp], sort=False, ignore_index=True)

"""##Keterangan Dataset
Penjelasan variabel dari data diatas sebagai berikut :

1. tanggal : Tanggal pengukuran kualitas udara
2. stasiun : Lokasi pengukuran di stasiun
3. pm10 : Partikulat salah satu parameter yang diukur
4. pm25 : Partikulat salah satu parameter yang diukur
5. so2 : Sulfida (dalam bentuk SO2) salah satu parameter yang diukur
6. co : Carbon Monoksida salah satu parameter yand diukur
7. o3 : Ozon salah satu parameter yang diukur
8. no2 : NItrogen dioksida salah satu parameter yang diukur
9. max : Nilai ukur paling tinggi dari seluruh parameter yang diukur dalam waktu yang sama
10. critical : Parameter yang hasil pengukurannya paling tinggi
11. categori : Kategori hasil perhitungan indeks standar pencemaran udara
"""

ispuRaw.describe(include = 'all')

"""##Remove Unnamed Columns"""

ispuRaw.columns

"""Dari fungsi ini, terdapat beberapa kolom yang tidak ada dalam penjelasan keterangan dataset, seperti `Unnamed: x`.

Selain itu ada juga beberapa kolom yang tidak konsisten, seperti kolom `so2` dengan `s02`, `categori` dengan `kategori` dan kolom `keterangan`.

Untuk itu, di tahap berikutnay akan dilakukan pembersihan dan normaliasi posisi data.

Step pertama ialah memeriksa isi dari kolom yang dengan format `Unnamed: x`
"""

ispuRaw[['Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12',
                        'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',
                        'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',
                        'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21']].describe()

"""Setelah diperiksa, isi dari kolom tersebut hanyalah **NaN**.
Untuk itu, kolom tersebut harus dihapus karena hanya berisi _noice_ data.
"""

ispuRaw = ispuRaw.drop(['Unnamed: 10', 'Unnamed: 11', 'Unnamed: 12',
                        'Unnamed: 13', 'Unnamed: 14', 'Unnamed: 15',
                        'Unnamed: 16', 'Unnamed: 17', 'Unnamed: 18',
                        'Unnamed: 19', 'Unnamed: 20', 'Unnamed: 21'], axis=1)

ispuRaw.columns

"""## Hapus baris dimana nilai kolom tanggal adalah NaN

Langkah berikutnya adalah memeriksa kolom `tanggal`. Kolom ini sangat vital karena kolom ini menjadi titik acuh untuk melakukan _forecasting_ di data _time series_. Untuk itu akan diperiksa total baris di kolom tanggal yang bernilai NaN
"""

ispuRaw['tanggal'].isna().sum()

"""Setelah dihitung, ternyata terdapat 205 data yang dimana kolom tanggalnya adalah NaN.
Langkah selanjutnya adalah memeriksa apakah data dimana nilai tanggal nya adalah NaN memiliki data yang bisa dipakai.
"""

print("Deskripsi Data")
print(ispuRaw.loc[ispuRaw['tanggal'].isna()].describe(include = 'all'))

print("\nTotal Data yang bukan nan ketika data tanggal nan")
ispuRaw.loc[ispuRaw['tanggal'].isna()].notna().sum()

"""Berdasarkan hasil berikut, ketika data di kolom tanggal adalah NaN, seluruh data yang mengikutinya juga NaN dan tidak ada data yang memiliki nilai. Untuk itu maka seluruh data yang tanggalnya NaN aman dihapus."""

ispuRaw = ispuRaw.dropna(subset=['tanggal'])

ispuRaw['tanggal'].isna().sum()

"""## Periksa format tanggal

Setelah membersihkan data tanggal yang Nan, langkah berikutnya adalah memeriksa format tanggal. Format yang dipakai dalam dataset ialah YYYY-MM-DD (Contoh : 2023-06-09).

Untuk memeriksa data yang memiliki tanggal yang berbeda dengan format dari datasetnya, dapat dilakukan dengan menjalankan cell berikut
"""

dayFirst = []
notDayFirst = []

def validate(date_text):
    try:
      datetime.date.fromisoformat(date_text)
    except ValueError:
      print(date_text)
      date_text_split = date_text.split('/')
      if (int(date_text_split[1]) > 12):
        notDayFirst.append(date_text)
      else:
        dayFirst.append(date_text)

for idx, data in ispuRaw[['tanggal']].iterrows():
  validate(data['tanggal'])

print(len(dayFirst), len(notDayFirst))

"""Disini dapat disimpulkan terdapat 274 data yang menggunakan format bukan YYYY-MM-DD. Dan setelah diperiksa, 274 data tersebut menggunakan format dimana hari merupakan baris pertamanya, sehingga 274 data tersebut menggunakan format DD/MM/YYYY. Untuk itu perlu dilakukan konversi ke format YYYY-MM-DD agar seragam dengan data lainnya."""

ispuRaw['tanggal'] = pd.to_datetime(ispuRaw['tanggal'], dayfirst=True)

"""Setelah melakukan konversi, maka dilakukan pemeriksaan dengan mengambil salah satu sampel tanggal yang bermasalah"""

ispuRaw.loc[ispuRaw['tanggal'] == datetime.datetime(2016,12,26)]

"""Disini dapat disimpulkan bahwa kelima stasiun tercatat dalam tabel tersebut, sehingga dapat disimpulkan bahwa konversi tanggal berhasil.

## Periksa kolom stasiun pemantauan

Setelah data pada kolom tanggal sudah normal dan bersih, kini saatnya memeriksa data stasiun pemantauan.

Berdasarkan keterangan dari dataset, ada 5 stasiun pemantauan pencemaran udara, yaitu:
1. DKI1 (Bunderan HI)
2. DKI2 (Kelapa Gading)
3. DKI3 (Jagakarsa)
4. DKI4 (Lubang Buaya)
5. DKI5 (Kebon Jeruk)

### Periksa kolom stasiun terdapat NaN

Tahap pertama ialah memeriksa apakah ada data stasiun yang NaN
"""

ispuRaw['stasiun'].isna().sum()

"""Ternyata ada 305 data yang NaN. Untuk itu perlu diperiksa kondisi baris yang data stasiunnya adalah NaN"""

ispuRaw.loc[(ispuRaw['stasiun'].isna())].head()

"""Setelah diperiksa, ternyata terjadi inkonsitensi urutan data dengan kolomnya, dimana kolom `location` berubah menjadi data untuk `categori`, data stasiun bergeser ke kolom `pm10` dan seterusnya.

Untuk itu perlu dilakukan normalisasi data dengan menggeser data ke kolom yang sebenarnya
"""

errorDatasDate = ispuRaw.loc[(ispuRaw['stasiun'].isna())]['tanggal'].values
errorISPUs = pd.DataFrame(ispuRaw.loc[ispuRaw['tanggal'].isin(errorDatasDate)])
for index, errorISPU in errorISPUs.iterrows():
    errorISPU['stasiun'] = errorISPU['pm10']
    errorISPU['pm10'] = errorISPU['pm25']
    errorISPU['pm25'] = errorISPU['so2']
    errorISPU['so2'] = errorISPU['co']
    errorISPU['co'] = errorISPU['o3']
    errorISPU['o3'] = errorISPU['no2']
    errorISPU['no2'] = errorISPU['max']
    errorISPU['max'] = errorISPU['critical']
    errorISPU['critical'] = errorISPU['categori']
    errorISPU['categori'] = errorISPU['location']
    ispuRaw.loc[index] = errorISPU

ispuRaw.loc[ispuRaw['tanggal'].isin(errorDatasDate)]

ispuRaw['stasiun'].isna().sum()

"""Setelah dilakukan pergeseran, maka tidak ada lagi stasiun yang NaN dan dapat melanjutkan tahap berikutnya

### Periksa data unik di kolom stasiun

Setelah memeriksa stasiun yang hilang, langkah berikut nya adalah memeriksa normalitas data stasiun. Dalam dataset, ada 5 Stasiun Pemantauan. Untuk memeriksanya, bisa dilakukan dengan melihat nilai unik dari kolom stasiun
"""

ispuRaw['stasiun'].describe()

ispuRaw['stasiun'].unique()

"""Setelah diperiksa, ternyata ada 55 nama stasiun di dalam kolom tersebut, dan setelah di periksa, ternyata selain ada 2 stasiun DKI5, ada beberapa angka ISPU dan karakter "---" didalam tersebut

Untuk memastikan nilai-nilai ISPU tersebut, maka perlu di index nama stasiun yang dipakai (termasuk duplikasi dari DKI5) dan mengambil data yang nama stasiunnya adalah nilai ISPU
"""

rawStations = ['DKI1 (Bunderan HI)', 'DKI2 (Kelapa Gading)', 'DKI3 (Jagakarsa)',
       'DKI4 (Lubang Buaya)', 'DKI5 (Kebon Jeruk)',
       'DKI5 (Kebon Jeruk) Jakarta Barat']
ispuRaw.loc[~ispuRaw['stasiun'].isin(rawStations)]

errorISPUDatas = ispuRaw.loc[~ispuRaw['stasiun'].isin(rawStations)]
errorDatasDate = ispuRaw.loc[~ispuRaw['stasiun'].isin(rawStations)]['tanggal'].values

currentAirPolutantComponents = {
    1.0: 'PM10',
    2.0: 'SO2',
    3.0: 'CO',
    4.0: 'O3',
    5.0: 'NO2'
}

df = pd.DataFrame(columns=['max', 'expectation', 'reality'])
df['max'] = errorISPUDatas['max']
df['expectation'] = [
    np.nan if pd.isnull(data) else currentAirPolutantComponents[data]
    for index, data in errorISPUDatas['max'].items()
    ]
df['reality'] = errorISPUDatas['critical']

df['expectation'].equals(df['reality'])

"""Disini dapat disimpulkan telah terjadi abnormal data dimana data tiap komponen pencemaran udara bergeser ke kolom stasiun, sehingga data pm10 berada di kolom stasiun, begitu seterusnya.

Sedangkan data di kolom max adalah nomor index dari kolom komponen udara, dimana 1 adalah pm10, begitu seterusnya.

### Perbaiki posisi data komponen udara
"""

stations = ['DKI1 (Bunderan HI)', 'DKI2 (Kelapa Gading)', 'DKI3 (Jagakarsa)',
       'DKI4 (Lubang Buaya)', 'DKI5 (Kebon Jeruk)']

stationsIndex = 0
count = 0
for index, errorISPU in errorISPUDatas.iterrows():
    errorISPU['max'] = errorISPU['no2']
    errorISPU['no2'] = errorISPU['o3']
    errorISPU['o3'] = errorISPU['co']
    errorISPU['co'] = errorISPU['so2']
    errorISPU['so2'] = errorISPU['pm10']
    errorISPU['pm10'] = errorISPU['stasiun']
    errorISPU['stasiun'] = stations[stationsIndex]
    count+=1
    if (count % 31 == 0): stationsIndex+=1
    ispuRaw.loc[index] = errorISPU

errorISPUDatas.index

ispuRaw.loc[errorISPUDatas.index]

ispuRaw['stasiun'].unique()

"""### Ubah kolom DKI5 (Kebon Jeruk) Jakarta Barat menjadi DKI5 (Kebon Jeruk)"""

ispuRaw.loc[ispuRaw['stasiun'] == rawStations[5], 'stasiun'] = rawStations[4]

ispuRaw['stasiun'].unique()

"""## Merge kolom Categori dengan kolom kategori"""

ispuRaw['categori'] = ispuRaw['categori'].combine_first(ispuRaw['kategori'])

"""## Merge kolom so2 dengan kolom s02"""

ispuRaw['so2'] = ispuRaw['so2'].combine_first(ispuRaw['s02'])

ispuRaw.describe(include = 'all')

"""## Hapus kolom location"""

ispuRaw = ispuRaw.drop(['location'], axis=1)

ispuRaw.describe(include = 'all')

"""## Hapus kolom Kategori dan s02"""

ispuRaw = ispuRaw.drop(['kategori', 's02'], axis=1)

ispuRaw.describe(include = 'all')

"""##Perbaiki baris data dimana data critical dan categori tidak sesuai dengan penjelasan variabel"""

ispuRaw.loc[(ispuRaw['keterangan'].notna())].head()

errorDatasDate = ispuRaw.loc[(ispuRaw['keterangan'].notna())]['tanggal'].values
errorISPUs = pd.DataFrame(ispuRaw.loc[ispuRaw['tanggal'].isin(errorDatasDate)])
for index, errorISPU in errorISPUs.iterrows():
    errorISPU['critical'] = errorISPU['categori']
    errorISPU['categori'] = errorISPU['keterangan']
    ispuRaw.loc[index] = errorISPU

ispuRaw.loc[(ispuRaw['keterangan'].notna())].head()

"""##Hapus kolom keterangan"""

ispuRaw = ispuRaw.drop(['keterangan'], axis=1)

ispuRaw.describe(include = 'all')

"""##Hapus baris data dimana kolom categori adalah "TIDAK ADA DATA"
"""

len(ispuRaw[ispuRaw['categori'] == 'TIDAK ADA DATA'])

ispuRaw.loc[ispuRaw['categori'] == 'TIDAK ADA DATA']

ispuRaw = ispuRaw[ispuRaw['categori'] != 'TIDAK ADA DATA']

(ispuRaw['categori'] == 'TIDAK ADA DATA').sum()

ispuRaw.describe(include = 'all')

"""##Periksa data critical dan categori yang unik"""

print(ispuRaw['critical'].unique())
print(ispuRaw['categori'].unique())

"""Disini ditemukan bahwa di kolom critical terdapat data 'BAIK' dimana data tersebut harusnya berada di kolom kategori, sedangkan di kolom categori terdapat nan.

##Periksa baris data dimana kolom critical adalah 'BAIK'
"""

ispuRaw.loc[ispuRaw['critical'] == 'BAIK']

"""Ternyata di index ke-21967 terdapat data yang abnormal, dimana kolom critical adalah "BAIK" dan categori adalah NaN, serta kolom max adalah "PM25" dimana harusnya data tersebut berada di kolom critical."""

ispuRaw.at[21967, 'categori'] = ispuRaw.loc[21967]['critical']
ispuRaw.at[21967, 'critical'] = ispuRaw.loc[21967]['max']
ispuRaw.at[21967, 'max'] = '0'
ispuRaw.loc[[21967]]

print(ispuRaw['critical'].unique())
print(ispuRaw['categori'].unique())

ispuRaw.describe(include = 'all')

"""##Ganti nilai ISPU komponen pencemaran udara yang hilang dengan NaN"""

ispuRaw[['pm10', 'so2', 'co', 'o3', 'no2', 'pm25']] = ispuRaw[['pm10', 'so2', 'co', 'o3', 'no2', 'pm25']].replace('---', np.nan)
ispuRaw[['pm10', 'so2', 'co', 'o3', 'no2', 'pm25']] = ispuRaw[['pm10', 'so2', 'co', 'o3', 'no2', 'pm25']].replace(pd.NA, np.nan)

ispuRaw.describe()

"""##Ubah tipe data nilai ISPU komponen pencemaran udara menjadi float64"""

import numpy as np
airPolutantComponents = ['pm10', 'pm25', 'so2', 'co', 'o3', 'no2']
for component in airPolutantComponents:
  ispuRaw[component] = pd.to_numeric(ispuRaw[component],
                                     errors='coerce') .astype(np.float64())

ispuRaw.describe()

"""##Set Nilai maksimal untuk data index ke-21967"""

ispuRaw.at[21967, 'max'] = int(ispuRaw.loc[[21967], airPolutantComponents].max(axis=1))

ispuRaw.loc[[21967]]

"""## Cek NaN setiap komponen pencemaran udara"""

ispuRaw[airPolutantComponents].isna().sum()

"""## Split tiap stasiun pemantauan

Untuk mempermudah analisis, perlu dilakukan pemisahan data antar stasiun untuk melihat karateristik masing-masing data
"""

grouped = ispuRaw.groupby(['stasiun'])
ispuDKI1 = grouped.get_group(stations[0])
ispuDKI2 = grouped.get_group(stations[1])
ispuDKI3 = grouped.get_group(stations[2])
ispuDKI4 = grouped.get_group(stations[3])
ispuDKI5 = grouped.get_group(stations[4])


airPolutantComponents = ['pm10', 'so2', 'co', 'o3', 'no2', 'pm25']

"""## Periksa Tanggal yang Duplikat

### Stasiun DKI1
"""

ispuDKI1['tanggal'].duplicated().sum()

ispuDKI1[ispuDKI1.duplicated('tanggal')]['tanggal']

"""Setelah di periksa, ternyata ada 27 tanggal yang duplikat dimana data yang bermasalah ada di bulan Oktober dan November 2016 serta data bulan Juni 2020

#### Analisis dan Perbaiki Data Bulan Oktober 2016
"""

ispuDKI1.loc[(ispuDKI1['tanggal'] >= '2016-10-01') & (ispuDKI1['tanggal'] <= '2016-10-15')]

"""Setelah di periksa, ternyata pada indeks ke 12502 harusnya data tersebut memiliki tanggal `2016-10-08`, namun di dataset tanggal tersebut adalah `2016-10-10`. Untuk itu tanggal pada data tersebut akan diganti ke tanggal `2016-10-08`"""

ispuDKI1.at[12502, 'tanggal'] = datetime.datetime(2016, 10, 8)

ispuDKI1.loc[(ispuDKI1['tanggal'] >= '2016-10-01') & (ispuDKI1['tanggal'] <= '2016-10-15')]

"""#### Analisis dan Perbaiki Data Bulan November 2016"""

ispuDKI1.loc[(ispuDKI1['tanggal'] >= '2016-11-01') & (ispuDKI1['tanggal'] <= '2016-11-15')]

"""Setelah di periksa, ternyata pada indeks ke 12657 dan 12658 data yang seharusnya memiliki tanggal `2016-11-08` dan `2016-11-09`. Untuk itu tanggal pada data tersebut akan diganti ke tanggal `2016-11-08` dan `2016-11-09`."""

ispuDKI1.at[12657, 'tanggal'] = datetime.datetime(2016,11,8)
ispuDKI1.at[12658, 'tanggal'] = datetime.datetime(2016,11,9)

ispuDKI1.loc[(ispuDKI1['tanggal'] >= '2016-11-01') & (ispuDKI1['tanggal'] <= '2016-11-15')]

"""#### Analisis dan Perbaiki Data Bulan Juni 2020"""

ispuDKI1.loc[(ispuDKI1['tanggal'] >= '2020-06-01') & (ispuDKI1['tanggal'] <= '2020-06-30')]

"""Setelah di periksa, setelah tanggal 06 Juni, seluruh data dari tanggal 7 hinggal tanggal 30 (Indeks 19231 hingga 19254) tercatat tanggal 06 Juni."""

startDate = 7
for idx in range(19231, 19255):
  ispuDKI1.at[idx, 'tanggal'] = datetime.datetime(2020, 6, startDate)
  startDate += 1

ispuDKI1.loc[(ispuDKI1['tanggal'] >= '2020-06-01') & (ispuDKI1['tanggal'] <= '2020-06-30')]

"""Setelah melakukan perbaikan data, maka seluruh tanggal pada data stasiun DKI1 sudah tidak ada yang duplikat"""

ispuDKI1.duplicated('tanggal').sum()

"""### Stasiun DKI2"""

ispuDKI2.duplicated('tanggal').sum()

ispuDKI2[ispuDKI2.duplicated('tanggal')]

"""Setelah di periksa, ternyata ada 63 data tanggal yang duplikat dimana data yang bermasalah ada di bulan Agustus, Oktober, November dan Desember 2016 serta data bulan Juni 2020

#### Analisis dan Perbaiki Data Bulan Agustus 2016
"""

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-08-01') & (ispuDKI2['tanggal'] <= '2016-08-31')]

"""Setelah diperiksa, terjadi perulangan di kolom tanggal dimana data setelah tanggal 31 Agustus adalah tanggal 1 Agustus kembali. Meskipun begitu, data di tanggal 1 Agustus pertama dan 1 Agustus perulangannya berbeda. Selain itu di perulangan bulan Agustus tersebut, tanggalnya berakhir di tanggal 30 Agustus. Diduga data yang salah tanggal tersebut sebenarnya data bulan September. Untuk memastikannya, akan dilakukan pengecekan data di bulan September"""

# Periksa data bulan September
ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-09-01') & (ispuDKI2['tanggal'] <= '2016-09-30')]

"""Setelah di periksa, ternyata data bulan September kosong. Bisa dipastikan data tanggal yang terulang tersebut adalah data bulan September"""

for idx in range(12375, 12405):
  ispuDKI2.at[idx, 'tanggal'] = ispuDKI2.at[idx, 'tanggal'].replace(month=9)

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-08-01') & (ispuDKI2['tanggal'] <= '2016-08-31')]

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-09-01') & (ispuDKI2['tanggal'] <= '2016-09-30')]

"""#### Analisis dan Perbaiki Data Bulan Oktober 2016"""

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-10-01') & (ispuDKI2['tanggal'] <= '2016-10-15')]

"""Setelah di periksa, ternyata pada indeks ke 12533 data yang seharusnya memiliki tanggal `2016-11-08`. Untuk itu tanggal pada data tersebut akan diganti ke tanggal `2016-11-08`."""

ispuDKI2.at[12533, 'tanggal'] = datetime.datetime(2016,10,8)

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-10-01') & (ispuDKI2['tanggal'] <= '2016-10-15')]

"""#### Analisis dan Perbaiki Data Bulan November 2016"""

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-11-01') & (ispuDKI2['tanggal'] <= '2016-11-15')]

"""Setelah di periksa, ternyata pada indeks ke 12687 dan 12688 data yang seharusnya memiliki tanggal `2016-11-08` dan `2016-11-09`. Untuk itu tanggal pada data tersebut akan diganti ke tanggal `2016-11-08` dan `2016-11-09`."""

ispuDKI2.at[12687, 'tanggal'] = datetime.datetime(2016,11,8)
ispuDKI2.at[12688, 'tanggal'] = datetime.datetime(2016,11,9)

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-10-01') & (ispuDKI2['tanggal'] <= '2016-10-15')]

"""#### Analisis dan Perbaiki Data Bulan Desember 2016"""

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-12-01') & (ispuDKI2['tanggal'] <= '2016-12-15')]

"""Setelah di periksa, ternyata pada indeks ke 12838 data yang seharusnya memiliki tanggal `2016-12-08`. Untuk itu tanggal pada data tersebut akan diganti ke tanggal `2016-12-08`."""

ispuDKI2.at[12838, 'tanggal'] = datetime.datetime(2016,12,8)

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2016-12-01') & (ispuDKI2['tanggal'] <= '2016-12-15')]

"""#### Analisis dan Perbaiki Data Bulan Juni 2020"""

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2020-06-01') & (ispuDKI2['tanggal'] <= '2020-06-30')]

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2020-06-01') & (ispuDKI2['tanggal'] <= '2020-06-30')].count()

"""Setelah di periksa, seluruh data bulan Juni (Indeks 19255 hingga 19284) tercatat tanggal 06 Juni."""

startDate = 1
for idx in range(19255, 19285):
  ispuDKI2.at[idx, 'tanggal'] = datetime.datetime(2020, 6, startDate)
  startDate += 1

ispuDKI2.loc[(ispuDKI2['tanggal'] >= '2020-06-01') & (ispuDKI2['tanggal'] <= '2020-06-30')]

"""Setelah melakukan perbaikan data, maka seluruh tanggal pada data stasiun DKI2 sudah tidak ada yang duplikat"""

ispuDKI2.duplicated('tanggal').sum()

"""### Stasiun DKI3"""

ispuDKI3.duplicated('tanggal').sum()

ispuDKI3[ispuDKI3.duplicated('tanggal', keep=False)]

"""Setelah di periksa, ternyata ada 63 data tanggal yang duplikat dimana data yang bermasalah ada di bulan Agustus, Oktober, November dan Desember 2016 serta data bulan Juni 2020.

Karena data yang bermasalah sama dengan di Stasiun DKI2, maka akan langsung dilakukan perbaikan data

#### Perbaikan Data Bulan Agustus 2016
"""

for idx in range(12405, 12435):
  ispuDKI3.at[idx, 'tanggal'] = ispuDKI3.at[idx, 'tanggal'].replace(month=9)

"""#### Perbaikan Data Bulan Oktober, November, dan Desember 2016"""

ispuDKI3.at[12564, 'tanggal'] = datetime.datetime(2016,10,8)
ispuDKI3.at[12717, 'tanggal'] = datetime.datetime(2016,11,8)
ispuDKI3.at[12718, 'tanggal'] = datetime.datetime(2016,11,9)
ispuDKI3.at[12869, 'tanggal'] = datetime.datetime(2016,12,8)

"""#### Analisis dan Perbaiki Data Bulan Juni 2020"""

startDate = 1
for idx in range(19285, 19315):
  ispuDKI3.at[idx, 'tanggal'] = datetime.datetime(2020, 6, startDate)
  startDate += 1

"""Setelah melakukan perbaikan data, maka seluruh tanggal pada data stasiun DKI3 sudah tidak ada yang duplikat"""

ispuDKI3.duplicated('tanggal').sum()

"""### Stasiun DKI4"""

ispuDKI4.duplicated('tanggal').sum()

ispuDKI4[ispuDKI4.duplicated('tanggal', keep=False)]

"""Setelah di periksa, ternyata ada 62 data tanggal yang duplikat dimana data yang bermasalah ada di bulan Agustus, Oktober, November dan Desember 2016 serta data bulan Juni 2020.

Karena data yang bermasalah sama dengan di Stasiun DKI2, maka akan langsung dilakukan perbaikan data

#### Perbaikan Data Bulan Agustus 2016
"""

for idx in range(12435, 12465):
  ispuDKI4.at[idx, 'tanggal'] = ispuDKI4.at[idx, 'tanggal'].replace(month=9)

"""#### Perbaikan Data Bulan Oktober, November, dan Desember 2016"""

ispuDKI4.at[12595, 'tanggal'] = datetime.datetime(2016,10,8)
ispuDKI4.at[12747, 'tanggal'] = datetime.datetime(2016,11,8)
ispuDKI4.at[12748, 'tanggal'] = datetime.datetime(2016,11,9)
ispuDKI4.at[12900, 'tanggal'] = datetime.datetime(2016,12,8)

"""#### Analisis dan Perbaiki Data Bulan Juni 2020"""

startDate = 1
for idx in range(19315, 19345):
  if (idx in ispuDKI4.index):
    ispuDKI4.at[idx, 'tanggal'] = datetime.datetime(2020, 6, startDate)
  startDate += 1

ispuDKI4.duplicated('tanggal').sum()

"""### Stasiun DKI5"""

ispuDKI5.duplicated('tanggal').sum()

ispuDKI5[ispuDKI5.duplicated('tanggal', keep=False)]

"""#### Perbaikan Data Bulan Agustus 2016"""

for idx in range(12465, 12495):
  ispuDKI5.at[idx, 'tanggal'] = ispuDKI5.at[idx, 'tanggal'].replace(month=9)

"""#### Perbaikan Data Bulan Oktober, November, dan Desember 2016"""

ispuDKI5.at[12626, 'tanggal'] = datetime.datetime(2016,10,8)
ispuDKI5.at[12777, 'tanggal'] = datetime.datetime(2016,11,8)
ispuDKI5.at[12778, 'tanggal'] = datetime.datetime(2016,11,9)
ispuDKI5.at[12931, 'tanggal'] = datetime.datetime(2016,12,8)

"""#### Analisis dan Perbaiki Data Bulan Juni 2020"""

startDate = 1
for idx in range(19345, 19350):
  if (idx in ispuDKI5.index):
    ispuDKI5.at[idx, 'tanggal'] = datetime.datetime(2020, 6, startDate)
  startDate += 1

ispuDKI5.duplicated('tanggal').sum()

"""# Exploratory Data Analysis (Data Visualisation and Analysis)

## Analisis Deskripsi Variabel Secara Umum
"""

print("Jumlah Missing Value Keseluruhan")
print(ispuRaw[airPolutantComponents].isna().sum())

print("\n\nJumlah Zero Value Keseluruhan")
print((ispuRaw[airPolutantComponents] == 0).sum())

print(100*ispuRaw['categori'].value_counts(normalize=True))
ispuRaw['categori'].value_counts().plot(kind='bar', title="Total Kategori ISPU Seluruh Stasiun")

"""Berdasarkan grafik ini dapat disimpulkan bahwa kategori ISPU maksimum di 5 stasiun SPKU di DKI Jakarta mayoritas kategori Sedang dengan persentase 66.76%, diikuti dengan kategori Baik dengan persentase 18.86%, Tidak Sehat dengan persentase 13.34%, Sangat Tidak Sehat dengan persentase 1.04% dan Berbahaya dengan persentase 0.005%"""

print(ispuRaw['stasiun'].value_counts())
ispuRaw['stasiun'].value_counts().plot(kind='bar', title="Total Data yang Dicatat Setiap Stasiun")

"""Berdasarkan grafik ini, total data ISPU yang dicatat oleh Stasiun DKI 1 sebesar 4273 data, DKI 2 sebesar 4032 data, DKI 3 sebesar 3980, DKI 4 sebesar 3974, dan DKI 5 sebesar 3277. Ini menunjukkan bahwa tidak semua stasiun melakukan pencatatan ISPU dalam satu hari yang sama.

## Buat Function untuk EDA
"""

def eda_line_visualization(stasiun, component, title=None, startDate=None, endDate=None):
  fig, ax = plt.subplots(figsize=(75,10))
  if (title is None):
    title = "Nilai ISPU {0} {1}".format(component.upper(),
                                                  stasiun['stasiun'].iloc[0])
  if (None in (startDate, endDate)):
    x = stasiun.index
    y = [val if pd.notna(val) else None for val in stasiun[component]]
    plt.title(title)
  else:
    x = stasiun.loc[startDate: endDate].index
    y = [val if pd.notna(val) else None for val in stasiun.loc[
        startDate : endDate, component]]
    plt.title("{0} {2} - {3}"
      .format(title,
              datetime.datetime.strptime(startDate, "%Y-%m-%d").strftime("%d %B/%y"),
              datetime.datetime.strptime(endDate, "%Y-%m-%d").strftime("%d %B/%y"),))

  ax.plot(x, y, marker='o')
  ax.xaxis.set_major_locator(YearLocator())
  plt.xlabel("Tahun")
  plt.ylabel("ISPU")
  plt.grid(True)
  plt.show()
  plt.close()

def eda_line_visualizations(stasiun, startDate=None, endDate=None):
  # Tampilkan time series line chart setiap komponen pencemar
  for component in airPolutantComponents:
    fig, ax = plt.subplots(figsize=(75,10))
    x = stasiun.index
    if (None in (startDate, endDate)):
      y = [val if pd.notna(val) else None for val in stasiun[component]]
      plt.title("Nilai ISPU {0} {1}".format(component.upper(),
                                            stasiun['stasiun'].iloc[0]))
    else:
      y = [val if pd.notna(val) else None for val in stasiun.loc[
          startDate : endDate, component]]
      plt.title("Nilai ISPU {0} {1} {2} - {3}"
        .format(component.upper(), stasiun['stasiun'].iloc[0],
                datetime.datetime.strptime(startDate, "%Y-%m-%d").strftime("%d %B/%y"),
                datetime.datetime.strptime(endDate, "%Y-%m-%d").strftime("%d %B/%y"),))

    ax.plot(x, y, marker='o')
    ax.xaxis.set_major_locator(YearLocator())
    plt.xlabel("Tahun")
    plt.ylabel("ISPU")
    plt.grid(True)
    plt.show()
    plt.close()

def eda_skew(stasiun, component=None, title=None):
  if(component is None):
    for component in airPolutantComponents:
      fig, ax = plt.subplots(figsize=(25,10))
      # Clear NaN before create histogram
      data_no_nan = stasiun[component].dropna().to_numpy()
      sns.histplot(data_no_nan, kde=True)
      ax.set_xlabel('ISPU')
      ax.set_ylabel('Frequency')
      ax.set_title('Histogram Distribusi Nilai ISPU {0} {1}\nSkew Score: {2} ; Kurtosis Score: {3}'.format(
          component.upper(), stasiun['stasiun'].iloc[0],
          stats.skew(list(data_no_nan)), stats.kurtosis(list(data_no_nan))))
      plt.show()
      plt.close()
  else:
    fig, ax = plt.subplots(figsize=(25,10))
    # Clear NaN before create histogram
    data_no_nan = stasiun[component].dropna().to_numpy()
    sns.histplot(data_no_nan, kde=True)
    ax.set_xlabel('ISPU')
    ax.set_ylabel('Frequency')
    if (title is None):
      ax.set_title('Histogram Distribusi Nilai ISPU {0} {1}\nSkew Score: {2} ; Kurtosis Score: {3}'.format(
          component.upper(), stasiun['stasiun'].iloc[0],
          stats.skew(list(data_no_nan)), stats.kurtosis(list(data_no_nan))))
    else:
      ax.set_title('{0}\nSkew Score: {1} ; Kurtosis Score: {2}'.format(
          title,
          stats.skew(list(data_no_nan)), stats.kurtosis(list(data_no_nan))))
    plt.show()
    plt.close()


def eda_stasiun(stasiun):
  # Tampilkan jumlah Missing Value komponen polutan
  print("Missing Value untuk stasiun", stasiun['stasiun'].iloc[0])
  print(stasiun[airPolutantComponents[:-1]].isna().sum())
  print("Total:", stasiun[airPolutantComponents[:-1]].isna().sum().sum(),
        end="\n\n")

  # Tampilkan jumlah value yang bernilai 0
  print("Zero Value untuk stasiun", stasiun['stasiun'].iloc[0])
  print((stasiun[airPolutantComponents[:-1]] == 0).sum())
  print("Total:", stasiun[airPolutantComponents[:-1]].isna().sum().sum(),
        end="\n\n")

  # Set tanggal menjadi indeks
  stasiun = stasiun.set_index('tanggal')

  # Tampilkan range tanggal awal dan akhir dari data
  print("Range tanggal pada data stasiun")
  print(stasiun.index.min(), stasiun.index.max(), end="\n\n")

  eda_line_visualizations(stasiun)
  return stasiun

"""## Analisis ISPU DKI 1 (Bundaran HI)

### Analisis General
"""

ispuDKI1[airPolutantComponents].describe()

"""Berdasarkan tabel diatas
* Kandungan PM10 mendominasi dengan nilai ISPU rata-rata sebesar 52.29 dengan nilai maksimum 104
* Kandungan O3 menempati urutan kedua dengan nilai ISPU rata-rata 49.41 dengan nilai maksimum 198
* Kandungan CO menempati urutan ketiga dengan nilai ISPU rata-rata 24.81 dengan nilai maksmimum 95
* Kandungan SO2 menempati urutan keempat dengan nilai ISPU rata-rata sebesar 18.03 dengan nilai maksimum 106
* Kandungan NO2 menempati urutan terakhir dengan nilai ISPU rata-rata 14.01 dan nilai maksimum 79
* Kandungan PM25 memiliki nilai ISPU rata-rata sebesar 69.07 dengan nilai maksimum 112
* Secara angka, komponen PM25 menempati urutan tertinggi walaupun pengukurannya dimulai di tahun 2021 (Penjelasan lengkap akan dibahas di segmen Pengukuran PM2.5)

### Analisis Data dan Visualisasi Setiap Komponen Pencemar
"""

ispuDKI1 = eda_stasiun(ispuDKI1)

"""**Berdasarkan hasil analisis _Missing Value_, _Zero Value_ serta tanggal _Range_ berikut**
* Data dari DKI1 dicatat mulai dari tanggal 01 Januari 2010 hingga 31 Desember 2021
* Secara total, terdapat 383 Data NaN dimana PM10, O3, dan NO3 merupakan komponen udara yang paling banyak data NaN
* Selain itu, seluruh nilai data > 0

**Berdasarkan diagram PM10 berikut**
* Berdasarkan diagram tahun 2010 hingga 2015, terdapat sebuah tren dimana setiap akhir tahun, pergerakan indeks akan turun
* Berdasarkan diagram tahun 2016 hingga 2021
  * Pergerakan indeks sangat bervariatif dan berfluktuatif
  * Pada awal tahun 2016, terjadi peningkatan indeks PM10 hingga mendekati 150, kemudian indeks perlahan menurun hingga berada di bawah level indeks 50 hingga menurun di akhir tahun
  * Pada tahun 2017, terjadi tren peningkatan hingga berada di puncak di pertengahan hingga mendekati akhir tahun, kemudian indeks menurun secara tajam di akhir tahun dan stagnan di bawah level 50 hingga awal tahun 2018
  * Pada tahun 2018, terjadi peningkatan indeks hingga melewati 120, setelah itu terjadi penurunan. Peningkatan secara besar kembali terjadi di bulan November hingga turun di bulan Desember akhir
  * Pada tahun 2019, pergerakan sangat fluktuatif, dimana nilai indeks terjadi peningkatan sangat tajam di awal tahun dan di akhir tahun indeks akan menurun dibandingkan dengan rata-rata indeks selama tahun tersebut hingga awal tahun 2020
  * Pada tahun 2020, setelah penurunan terjadi tren peningkatan sejak bulan Maret hingga mengalami penurunan secara tajam sejak memasuki bulan November 2020. Peningkatan terjadi di akhir November dan mulai turun dan stagnan di bulan Desember hingga akhir tahun 2020
  * Pada tahun 2021, tren indeks sempat tinggi di Januari kemudian selama Febuari mengalami stagnasi hingga perlahan mengalami peningkatan dari Maret hingga Agustus dan September. Setelah itu mengalami tren penurunan hingga akhir November dan kembali mengalami peningkatan di Desember

**Berdasarkan diagram O3 berikut**
* Selama tahun 2010 hingga 2012 terjadi tren peningkatan indeks O3, kemudian terjadi penurunan hingga awal tahun 2016
* Pada tahun 2016, setelah terjadi peningkatan yang tajam di awal bulan, tren penurunan kembali terjadi hingga pertengahan tahun, kemudian perlahan naik hingga kembali turun di akhir tahun
* Pada tahun 2017, indeks mengalami tren peningkatan yang cukup besar hingga mendekati akhir tahun dan mengalami penurunan hingga awal tahun 2018
* Pada tahun 2018 terjadi peningkatan mendekati pertengahan tahun dan mendekati akhir tahun
* Pada tahun 2019 diawali dengan peningkatan indeks yang sangat tajam hingga mendekati level 200, selain itu terjadi tren peningkatan hingga mendekati akhir tahun dan mengalami tren penurunan hingga mendekati pertengahan tahun 2020
* Pada tahun 2020 terjadi peningkatan hingga mengalami penurunan secara dalam mendekati akhir tahun kemudian mulai meningkat di akhir tahun
* Pada tahun 2021 terdapat tren peningkatan hingga pertengahan tahun kemudian mengalami penurunan dan peningkatan di akhir tahun. Meskipun begitu, tingkat indeks dan fluktuasi di tahun 2021 lebih rendah dibandingkan dengan tahun-tahun sebelumnya

**Berdasarkan diagram SO2 berikut**
* Dari 2010 hingga 2012 terjadi tren peningkatan indeks SO2.
* Pada akhir tahun 2012, terjadi penurunan hingga awal tahun 2013
* Meskipun awal tahun 2013 pergerakan indeks bersifat stagnan, namun perlahan terjadi peningkatan nilai indeks hingga mendekati akhir tahun, setelah itu terjadi penurunan hingga awal tahun 2014
* Pada tahun 2014 kembali terjadi tren peningkatan. Peningkatan paling pesat terjadi pada bulan April dan mulai mengalami penurunan di akhir tahun
* Pada tahun 2015 terjadi peningkatan yang cukup pesat, terutama di bulan April dan pali besar terjadi di bulan Juni hingga Oktober, setelah itu terjadi penurunan dan sempat meningkat di awal Desember yang setelah itu kembali stagnan hingga akhir tahun
* Pada awal tahun 2016 terjadi peningkatan yang sangat tajam dan mulai menurun di pertengahan bulan Febuari. Pada bulan Maret hingga April, indeks mengalami stagnasi dan mulai April pertengahan mengalami tren kenaikan secara perlahan hingga tahun 2017 awal
* Pada awal tahun 2017, grafik terputus yang disebabkan indeks SO2 di tanggal tersebut tidak tercatat, namun bisa terlihat dari data-data berikutnya, posisi indeks berada lebih rendah dibandingkan indeks di awal tahun. Kemungkinan di antara tanggal dimana indeks SO2 tidak tercatat, telah terjadi tren penurunan indeks.
* Di bulan Febuari 2017 kembali terjadi tren peningkatan indeks SO2 dan mengalami perlambatan sejak di pertengahan November, namun tetap terjadi peningkatan indeks hingga akhir tahun
* Pada tahun 2018, peningkatan indeks tetap terus terjadi  hingga mengalami penurunan di pertengahan tahun, kemudian kembali terjadi peningkatan hingga pada akhir tahun terjadi penurunan
* Pada tahun 2019, indeks tetap bergerak naik dan pada bulan Maret akhir terjadi penurunan yang cukup besar. Setelah penurunan, indeks tetap stagnan di dibawah level 20 ISPU hingga mengalami peningkatan kembali di awal Juli. Tren ini terus berlangsung meskipun bergerak lambat hingga awal tahun 2020
* Pada tahun 2020 terjadi lonjakan kenaikan indeks SO2 hingga melampaui level 60 ISPU. Setelah itu terjadi tren penurunan hingga pertengahan bulan dan mulai meningkat hingga terjadi peningkatan yang sangat tajam di bulan November dan menurun hingga awal Desember. Setelah itu indeks kembali mulai stagnasi hingga akhir tahun
* Pada tahun 2021 indeks bergerak menurun kemudian kembali naik dengan cukup cepat hingga pada akhir tahun, indeks sudah menyentuk di level antara level 40 dan 60 ISPU

**Berdasarkan diagram NO2 berikut**
* Pada tahun 2010 hingga 2015, pergerakan indeks NO2 mengalami satu tren yang sama dimana indeks akan meningkat hingga pertengahan tahun dan mengalami penurunan di akhir dan awal tahun berikutnya
* Pada tahun 2015 akhir terjadi penurunan yang signifikan sehingga pada akhir tahun 2015 hingga pertengahan Januari 2017, indeks bergerak stagnan mendekati level 5 ISPU
* Kemudian terjadi peningkatan secara perlahan hingga di Oktober-November 2017 terjadi penurunan dan kembali stagnan hingga akhir 2019
* Setelah itu terjadi peningkatan yang cukup drastis hingga pertengahan tahun 2019. Setelah itu terjadi stagnasi dan kembali menurun mendekati akhir tahun
* Pada tahun 2020, terjadi peningkatan di awal tahun dan terjadi stagnasi hingga secara perlahan menurun di akhir Maret
* Setelah memasuki bulan Maret 2020, terjadi peningkatan secara lambat hingga terjadi puncaknya dimana pergerakan indeks meningkat drastis di akhir Oktober dan November 2020. Indeks kembali menurun dengan tajam di akhir November dan penurunan melambat hingga mendekati akhir tahun.
* Di akhir tahun 2020, indeks bergerak naik hingga mencapai puncaknya di Juni 2021, kemduian menurun di bulan Juli dan perlahan naik hingga akhir Oktober.
* Setelah itu terjadi penurunan yang tajam, dan tidak lama berselang terjadi fluktuasi yang tajam hingga kembali turun dan perlahan memulai tren kenaikan indeks di akhir tahun

**Berdasarkan diagram CO berikut**
* Berdasarkan data di tahun 2010 hingga 2015, indeks CO mengalami tren kenaikan dan penurunan secara rutin dengan detail sebagai berikut
  * Sejak 2010, indeks CO mengalami tren peningkatan dan beberapa bulan kemudian, indeks perlahan mengalami penurunan hingga di pertengahan tahun 2011
  * Setelah pertengahan tahun 2011, indeks mengalami peningkatan yang lambat hingga awal tahun 2012
  * Di tahun 2012, indeks mengalami fluktuatif dimana di separuh pertama tahun menglami penurunan sebanyak dua kali, kemudian di bulan Agustus mengalami penurunan paling rendah, setelah itu kembali meningkat hingga pengalami penurunan kembali di Desember
  * Di tahun 2013 diawali dengan peningkatan indeks yang cukup besar, kemudian dilanjutkan dengan fluktuatifnya indeks dimana terjadi kenaikan yang paling besar di pertengahan bulan diikuti dengan penurunan yang tajam setelahnya. Setelah itu indeks berangsur-angsur menaik walaupun pergerakannya sangat fluktuatif hingga akhir tahun
  * Indeks mengalami penurunan paling besar di akhir tahun 2014 dan awal tahun 2015, akhir April dan awal Bulan Mei 2015 dan bulan Agustus 2015
  * Indeks mulai menurun di akhir tahun 2015
* Bedasarkan data di tahun 2016 hingga 2021, pergerakan indeks CO tidak sebesar di _range_ waktu sebelumnya dengan detail sebagai berikut
  * Di awal tahun 2016, indeks mengalami peningkatan yang konsisten dan sempat melewati level 50 ISPU. Namun setelah itu, indeks tidak pernah melewati level 50 ISPU dan sejak mendekati akhir tahun, indeks bergerak menurun hingga akhir tahun
  * Di tahun 2017, indeks kembali menaik, meskipun tidak sebesar tahun sebelumnya namun setelahnya indeks justru semakin menurun. Peningkatan sempat kembali terjadi di pertengahan September, meskipun peningkatannya sangat fluktuatif. Di bulan November, indeks perlahan menurun dan mulai berada di rata-rata level di bawah 25 ISPU hingga akhir tahun
  * Di tahun 2018, tren serupa kembali terjadi, namun di tahun tersebut, tingkat penurunan indeksnya lebih besar dan lebih lama dibandingkan dengan tahun lalu
  * Di tahun 2019, indeks kembali mengalami apa yang terjadi di dua tahun sebelumnya dimana di awal tahun mengalami peningkatan yang peningkatan kemudian di pertengahan tahun mengalami penurunan. Namun di tahun ini, terjadi peningkatan cukup konsisten di akhir tahun hingga puncaknya terjadi di awal tahun 2020
  * Di awal tahun 2020, indeks pengalami puncak kenaikannya sejak akhir tahun lalu, dan kemudian melandai dengan cukup dalam di pertengahan tahun, meskipun sempat mengalami peningkatan yang drastis menjelang akhir tahun, namun indeks kembali menurun di bawah level 10 ISPU hingga akhir tahun.
  * Di tahun 2021, indeks mengalmi kenaikan, meskipun begitu indeks bergerak sangat fluktuatif rata-rata berada di _range_ 10 hingga 25 ISPU, dan setelah itu mengalami penurunan rata-rata nya di pertengahan tahun hingga akhir tahun mengalami tren kenaikan

### Analisis Skew dan Kurtosis
"""

eda_skew(ispuDKI1)

"""Berdasarkan histogram berikut, seluruh histogram selain Histogram PM10 dan PM2.5 memiliki distribusi positif dimana _tail_ kanan lebih panjang dibandingkan _tail_ kiri dimanai skor skew rata-rata berada diluar range -0.5 sampai 0.5

## Analisis ISPU DKI 2 (Kelapa Gading)

### Analisis General
"""

ispuDKI2[airPolutantComponents].describe()

"""Berdasarkan tabel diatas
* Kandungan O3 mendominasi dengan nilai ISPU rata-rata sebesar 76.47 dengan nilai maksimum 314
* Kandungan PM10 menempati urutan kedua dengan nilai ISPU rata-rata 55.20 dengan nilai maksimum 116
* Kandungan SO2 menempati urutan ketiga dengan nilai ISPU rata-rata 20.44 dengan nilai maksmimum 103
* Kandungan CO menempati urutan keempat dengan nilai ISPU rata-rata sebesar 18.50 dengan nilai maksimum 75
* Kandungan NO2 menempati urutan terakhir dengan nilai ISPU rata-rata 15.09 dan nilai maksimum 148
* Kandungan PM25 memiliki nilai ISPU rata-rata sebesar 76.65 dengan nilai maksimum 129
* Secara angka, komponen PM25 menempati urutan tertinggi walaupun pengukurannya dimulai di tahun 2021 (Penjelasan lengkap akan dibahas di segmen Pengukuran PM2.5)

### Analisis Data dan Visualisasi Setiap Komponen Pencemar
"""

ispuDKI2 = eda_stasiun(ispuDKI2)

"""**Berdasarkan hasil analisis _Missing Value_, _Zero Value_ serta tanggal _Range_ berikut**
* Data dari DKI2 dicatat mulai dari tanggal 04 November 2010 hingga 31 Desember 2021
* Secara total, terdapat 312 Data NaN dimana PM10, SO2, dan O3 merupakan komponen udara yang paling banyak data NaN
* Selain itu, seluruh nilai data > 0

**Berdasarkan diagram PM10 berikut**
* Dari tahun 2010 akhir hingga 2012, terdapat _tren_ dimana dari awal tahun terjadi kenaikan indeks hingga pertengahan tahun, kemudian disusul dengan penurunan hingga akhir tahun
* Namun, mulai dari tahun 2013 hingga 2015, dimana terjadi penurunan di pertengahan tahun dimana penurunan tersebut cukup dalam, namun akan kembali naik dan akan menurun di akhir tahun.
* Sejak tahun 2016, pergerakan sangat _seasonial_ dan mirip dengan situasi sebelum tahun 2013

**Berdasarkan diagram O3 berikut**
* Dari akhir tahun 2010 hingga mendekati akhir tahun 2012, terjadi tren peningkatan indeks O3, meskipun sempat menurun di awal tahun 2012 dan pertengahan tahun 2012, namun secara garis besar, tren bergerak menaik
* Setelah itu tren bergerak turun hingga memasuki tahun 2013 dimana hingga tahun 2015 terdapat tren dimana akan terjadi kenaikan sebanyak 2 kali di mendekati dan setelah pertengahan tahun, dan akan menurun di pertengahan tahun dan akhir tahun
* Di tahun 2016, pergerakan terlihat sangat berfluktuatif, meskipun di awal dan akhir tahun terjadi penurunan
* Di tahun 2017 hingga 2019, terdapat tren pergerakan dimana indeks akan bergerak naik hingga pertengahan tahun dan akan turun hingga akhir tahun
* Pada tahun 2018, tren terlihat berbeda dimana kenaikannya paling tinggi  hingga beberapa kali melewati batas 200 ISPU
* Di tahun 2020, indeks bergerak mirip dengan di tahun 2016, namun terjadi penurunan paling dalam mendekati akhir tahun 2020
* Di tahun 2021, indeks bergerak stagnan setelah awal tahun mengalami penurunan

**Berdasarkan diagram SO2 berikut**
* Sejak akhir tahun 2010 hingga 2017, pergerakan bergerak secara _seasional_ dimana indeks akan bergerak naik dan akan turun mendekati akhir tahun
* Di tahun 2018, indeks justru menurun dan stagnan mendekati pertengahan tahun hingga akhir tahun
* Di tahun 2019, indeks kembali menurun setelah awal tahun dan bergerak stagnan dan tidak sefluktuatif di tahun sebelumnya
* Di tahun 2020, indeks mulai bergerak mirip seperti sebelum tahun 2018, namun pergerakan mendekati akhir tahun mengalami peningkatan sangat tinggi, setelah itu kembali jatuh dan bergerak menurun di awal tahun berikutnya
* Di tahun 2021, meskipun masih sangat fluktuatif seperti tahun lalu dan pergerakan naiknya cukup tajam, namun pola yang dibentuk mulai mendekati seperti pola sebelum tahun 2018, meskipun sempat mengalami penurunan yang sangat tajam mendekati akhir tahun

**Berdasarkan diagram NO2 berikut**
* Pergerakan indeks sejak 2010 akhir hingga 2019 pertengahan mengalami stagnasi dimana tidak terlihat terjadinya tren kenaikan atau penurunan secara garis besar
* Pada tahun 2019 hingga pertengahan 2020, indeks mulai bergerak menurun meskipun lambat dan tidak terlalu besar
* Mendekati pertengahan tahun 2020, indeks mulai bergerak naik dan setelahnya mengalami kenaikan yang signifikan hingga menembus level 140 ISPU, setelah itu indeks turun dengan tajam
* Di akhir tahun 2020 hingga 2021, indeks mulai menunjukan pergerakan menaik secara perlahan, hingga indeks telah melewati level 40 ISPU

**Berdasarkan diagram CO berikut**
* Berdasarkan data tahun 2011 hingga 2015 terdapat pola dimana di akhir dan awal tahun berikutnya terjadi peningkatan indeks, selain itu indeks juga meningkat mendekati pertengahan bulan atau awal bulan
* Peningkatan terbesar terjadi di awal tahun 2015
* Pada tahun 2016, indeks bergerak sedikit berbeda dimana terjadi fluktuasi, dan mengalami penurunan di akhir tahun
* Pada awal tahun 2017, indeks menurun dan mulai mengalami pola yang terjadi sebelum tahun 2015
* Sejak tahun 2018 hingga 2021, pola bergerak dimana sempat mengalami peningkatan di awal tahun dan menurun di pertengahan tahun, kemudian meningkat di akhir tahun, namun di tahun 2021, pergerakan tidak sefluktuatif di tahun-tahun sebelumnya

### Analisis Skew dan Kurtosis
"""

eda_skew(ispuDKI2)

"""Berdasarkan histogram berikut, seluruh histogram selain Histogram PM10 dan PM2.5 memiliki distribusi positif dimana _tail_ kanan lebih panjang dibandingkan _tail_ kiri dimanai skor skew rata-rata berada diluar range -0.5 sampai 0.5

## Analisis ISPU DKI 3 (Jakagarsa)

### Analisis General
"""

ispuDKI3[airPolutantComponents].describe()

"""Berdasarkan tabel diatas
* Kandungan O3 mendominasi dengan nilai ISPU rata-rata sebesar 69.01 dengan nilai maksimum 118
* Kandungan PM10 menempati urutan kedua dengan nilai ISPU rata-rata 43.55 dengan nilai maksimum 274
* Kandungan CO menempati urutan ketiga dengan nilai ISPU rata-rata 19.94 dengan nilai maksmimum 98
* Kandungan SO2 menempati urutan keempat dengan nilai ISPU rata-rata sebesar 15.74 dengan nilai maksimum 112
* Kandungan NO2 menempati urutan terakhir dengan nilai ISPU rata-rata 8.79 dan nilai maksimum 107
* Kandungan PM25 memiliki nilai ISPU rata-rata sebesar 74.24 dengan nilai maksimum 132
* Secara angka, komponen PM25 menempati urutan tertinggi walaupun pengukurannya dimulai di tahun 2021 (Penjelasan lengkap akan dibahas di segmen Pengukuran PM2.5)

### Analisis Data dan Visualisasi Setiap Komponen Pencemar
"""

ispuDKI3 = eda_stasiun(ispuDKI3)

"""**Berdasarkan hasil analisis _Missing Value_, _Zero Value_ serta tanggal _Range_ berikut**
* Data dari DKI3 dicatat mulai dari tanggal 07 November 2010 hingga 31 Desember 2021
* Secara total, terdapat 704 Data NaN dimana PM10, SO2, dan O3 merupakan komponen udara yang paling banyak data NaN
* Selain itu, seluruh nilai data > 0 kecuali SO2 dimana terdapat 30 data yang bernilai 0

**Berdasarkan diagram PM10 berikut**
* Nilai PM10 mengalami tren penurunan dimulai di akhir 2012 hingga akhir 2015
* Terjadi peningkatan mulai tahun 2016 dan berada di puncaknya di tahun 2017
* Setelah itu terjadi penurunan di akhir tahun 2017 hingga merangkak naik di awal tahun 2018
* Sejak 2018, nilai ISPU PM10 mengalami tren _seasonial_ hingga akhir 2021

**Berdasarkan diagram O3 berikut**
* Nilai O3 umumnya mengalami tren penurunan menjelang akhir tahun hingga awal tahun berikutnya.
* Berdasarkan data tahun 2010 hingga 2015
  * Nilai O3 mencapat puncaknya di bulan November 2010 dan Oktober - November 2012
  * Penurunan nilai O3 cukup drastis terjadi akhir tahun 2014, awal dan akhir tahun 2015
* Berdasarkan data tahun 2016 hingga 2021
  * Pola musiman dimana setiap akhir dan awal tahun, kadar O3 menurun terap terjadi
  * Meskipun begitu, penurunan di akhir tahun 2018 hingga awal tahun 2019 tidak sebesar tahun-tahun sebelumnya
  * Terjadi penurunan kadar O3 secara drastis sejak akhir tahun 2020 hingga akhir tahun 2021
  * Meskipun sempat terjadi lonjakan yang cukup tajam di sekitar pertengahan tahun 2021
  * Terjadinya penurunan kadar O3 secara drastis sejak akhir tahun 2020 bertepatan kebijakan PSBB total dan PPKM yang berlaku di Jakarta waktu itu.

**Berdasarkan diagram SO2 berikut**
* Adanya pola _seasional_ yang terjadi dari Desember 2010 hingga pertengahan 2017
* Selain itu sejak tahun 2010 hingga 2014, nilai ISPU SO2 mengalami tren penurunan hingga awal tahun berikutnya.
* Berdasarkan data dari tahun 2010 hingga 2015
  * Secara perlahan dan pasti, nilai ISPU SO2 mengalami peningkatan.
  * Puncak nilai SO2 berada di tahun 2014 dan 2015, terutama menjelang akhir tahun.
  * Pada tahun 2015, nilai SO2 tetap tinggi hingga akhir tahun
* Berdasarkan data dari tahun 2016 hingga 2021
  * Tren peningkatan SO2 sempat menurun di sekitar Febuari dan Maret 2016, dan secara perlahan merangkak naik hingga tahun 2017 pertengahan
  * Setelah itu, nilai SO2 menurun drastis dan berikutnya secara berangsur menurun hingga mengalami peningkatan secara perlahan di tahun 2020 awal hingga pertengahan
  * Setelah sempat mengalami penurunan di pertengahan tahun 2020, nilai SO2 mengalami peningkatan secara tajam, terutama mendekati akhir tahun 2020.
  *  Meski sempat menurun di akhir tahun 2020 dan awal tahun 2021, nilai SO2 mengalami peningkatan hingga mendekati pertengahan tahun, dan kembali meningkat setelah sempat mengalami penurunan yang cukup besar hingga akhir tahun.

**Berdasarkan diagram NO2 berikut**
* Terdapat pola _seasional_ dimana nilai NO2 akan mengalami penurunan di setiap akhir hingga awal tahun berikutnya.
* Meskipun begitu, ada beberapa hari yang tidak tercatat oleh stasiun pemantauan, terutama di akhir tahun 2013 hingga awal tahun 2014
* Berdasarkan data dari tahun 2010 hingga 2015
  * Kadar NO2 umumnya mengalami peningkatan di pertengahan tahun, kecuali di tahun 2014 dan 2015
  * Pada tahun 2014 dan 2015, kadar NO2 mengalami peningkatan menjelang dan akhir pertengahan tahun
* Berdasarkan data dari tahun 2016 hingga 2021
  * Meskipun membentuk pola yang mirip dengan _range_ tahun 2010 hingga 2015, namun pola di _range_ ini sedikit berfluaktif
  * Pada akhir pertengahan 2016, nilai NO2 sempat mengalami peningkatan hingga nilai ISPU melewati 20.
  * Sedangkan pada tahun 2020, terjadi peningkatan indeks NO2 yang sangat drastis hingga melewati ISPU 100

**Berdasarkan diagram CO berikut**
* Indeks CO mengalami peningkatan yang cukup tajam di awal tahun 2011 dan kembali menurun menjelang pertengahan tahun 2011
* Kemudian sejak pertengahan tahun 2012, nilai indeks mengalami tren penurunan hingga pertengahan tahun 2013
* Namun Indeks CO mengalami peningkatan yang cukup besar sejak pertengahan tahun 2013
* Indeks CO kembali mengalami penurunan sejak awal tahun 2016 hingga pertengahan tahun 2017
* Setelah itu indeks CO perlahan naik hingga berada di puncaknya di awal tahun 2020
* Setelah itu tren penurunan kembali terjadi dan mengalami stagnansi sejak akhir tahun 2020 hingga akhir tahun 2021

### Analisis Skew dan Kurtosis
"""

eda_skew(ispuDKI3)

"""Berdasarkan histogram berikut, seluruh histogram selain Histogram PM10 dan PM2.5 memiliki distribusi positif dimana _tail_ kanan lebih panjang dibandingkan _tail_ kiri dimanai skor skew rata-rata berada diluar range -0.5 sampai 0.5

## Analisis ISPU DKI 4 (Lubang Buaya)

### Analisis General
"""

ispuDKI4[airPolutantComponents].describe()

"""Berdasarkan tabel diatas
* Kandungan PM10 mendominasi dengan nilai ISPU rata-rata sebesar 63.13 dengan nilai maksimum 179
* Kandungan O3 menempati urutan kedua dengan nilai ISPU rata-rata 60.97 dengan nilai maksimum 236
* Kandungan SO2 menempati urutan ketiga dengan nilai ISPU rata-rata sebesar 20.76 dengan nilai maksimum 72
* Kandungan CO menempati urutan keempat dengan nilai ISPU rata-rata 17.61 dengan nilai maksmimum 134
* Kandungan NO2 menempati urutan terakhir dengan nilai ISPU rata-rata 12.30 dan nilai maksimum 107
* Kandungan PM25 memiliki nilai ISPU rata-rata sebesar 93.17 dengan nilai maksimum 174
* Secara angka, komponen PM25 menempati urutan tertinggi walaupun pengukurannya dimulai di tahun 2021 (Penjelasan lengkap akan dibahas di segmen Pengukuran PM2.5)

### Analisis Data dan Visualisasi Setiap Komponen Pencemar
"""

ispuDKI4 = eda_stasiun(ispuDKI4)

"""**Berdasarkan hasil analisis _Missing Value_, _Zero Value_ serta tanggal _Range_ berikut**
* Data dari DKI4 dicatat mulai dari tanggal 04 November 2010 hingga 31 Desember 2021
* Secara total, terdapat 846 Data NaN dimana O3, CO, dan PM10 merupakan komponen udara yang paling banyak data NaN
* Selain itu, seluruh nilai data > 0 kecuali SO2 dimana terdapat 25 data dan CO sebanyak 12 data yang bernilai 0

**Berdasarkan diagram PM10 berikut**
* Indeks PM10 mengalami tren penurunan setiap akhir tahun dan awal tahun. Tren tersebut terjadi hampir di setiap tahunnya
* Indeks PM10 mengalami tren peningkatan setiap menjelang dan pertengahan tahun
* Peningkatan yang besar terjadi di tahun 2011, 2012, 2019 dan 2020
* Peningkatan PM10 di tahun 2020 terjadi justru di awal tahun
* Indeks PM10 mengalami penurunan yang sangat drastis di tahun 2021

**Berdasarkan diagram O3 berikut**
* Secara umum, kadar O3 mengalami penurunan di akhir dan awal tahun
* Pada akhir tahun 2013 hingga awal tahun 2014 indeks O3 mengalami peningkatan
* Pada akhir tahun 2014, indeks sempat meningkat tajam hingga melewati 200 sebelum kembali turun dengan tajam dibawah 50
* Pada tahun 2019, indeks mengalami tren peningkatan yang cukup panjang sejak mendekati pertengahan tahun hingga akhir tahun.
* Pada awal tahun 2020, indeks meningkat dengan tajam sebelum mengalami penurunan yang cukup besar sejak pertengahan hingga akhir tahun
* Pada tahun 2021, indeks stagnan dan rata-rata berada dibawah 50, walaupun mendekati akhir tahun sempat meningkat hingga hampir melewati 75

**Berdasarkan diagram SO2 berikut**
* Terjadi tren peningkatan indeks SO2 sejak tahun 2013 hingga awal tahun 2016 sebelum terjadi penurunan
* Setelah penurunan, tren kembali meningkat hingga mendekati akhir tahun 2017 sebelum terjadi penurunan ke level dibawah 30
* Pada awal tahun 2018, indeks mengalami peningkatan sangat tajam hingga melewati level 70, kemudian mengalami penurunan secara tajam hingga dibawah level 10.
* Namun indeks SO2 mengalami peningkatan hingga mendekati akhir tahun 2018.
* Sejak tahun 2019, indeks SO2 mengalami peningkatan dan akan turun di akhir tahun atau awal tahun berikutnya. hal tersebut terjadi terus menerus hingga akhir tahun 2021

**Berdasarkan diagram NO2 berikut**
* Melihat dari data indeks NO2 di tahun 2010 hingga 2019 akhir, indeks NO2 berada di posisi stagnan dimana tidak terlalu banyak peningkatan indeks secara signifikan dan rata-rata kenaikan tertinggi berada di level 30
* Pada akhir tahun 2019, indeks NO2 mengalami penurunan dibandingkan tahun sebelumnya
* Namun, pada tahun 2020, terjadi 2 kali peningkatan indeks NO2 secara drastis, dimana pada bulan Maret terjadi peningkatan di level indeks 70, kemudian pada bulan Oktober, terjadi peningkatan yang sangat signifikan yaitu melewati level index 100 dan setelah memasuki bulan November, indeks menurun ke level mendekati seperti di bulan Januari
* Memasuki tahun 2021, indeks NO2 perlahan mengalami kenaikan dan di akhir tahun 2021 indeks perlahan menurun walaupun mendekati akhir tahun kembali meningkat

**Berdasarkan diagram CO berikut**
* Indeks CO mengalami peningkatan besar di awal dan menjelang akhir tahun 2012, pertengahan akhir tahun 2016, awal tahun 2020 dan akhir tahun 2020
* Penurunan indeks CO yang besar terjadi di pertengahan tahun 2012, menjelang akhir tahun 2014 dan pertengahan hingga akhir tahun 2016
* Pada tahun 2021, pergerakan indeks CO tidak terlalu fluaktif seperti di tahun-tahun sebelumnya dimana rata-rata indeks CO di tahun 2021 adalah 12.15

### Analisis Skew dan Kurtosis
"""

eda_skew(ispuDKI4)

"""Berdasarkan histogram berikut, seluruh histogram selain Histogram SO2 dan PM2.5 memiliki distribusi positif dimana _tail_ kanan lebih panjang dibandingkan _tail_ kiri dimanai skor skew rata-rata berada diluar range -0.5 sampai 0.5.

Meskipun begitu, pada Histogram SO2 ada 2 titik puncak dimana titik puncak tertinggi berada pada range 0-10.

## Analisis ISPU DKI 5 (Kebon Jeruk)

### Analisis General
"""

ispuDKI5[airPolutantComponents].describe()

"""Berdasarkan tabel diatas
* Kandungan O3 mendominasi dengan nilai ISPU rata-rata sebesar 67.44 dengan nilai maksimum 243
* Kandungan PM10 menempati urutan kedua dengan nilai ISPU rata-rata 48.56 dengan nilai maksimum 114
* Kandungan CO menempati urutan ketiga dengan nilai ISPU rata-rata sebesar 22.94 dengan nilai maksimum 243
* Kandungan SO2 menempati urutan keempat dengan nilai ISPU rata-rata 13.70 dengan nilai maksmimum 51
* Kandungan NO2 menempati urutan terakhir dengan nilai ISPU rata-rata 11.21 dan nilai maksimum 135
* Kandungan PM25 memiliki nilai ISPU rata-rata sebesar 78.82 dengan nilai maksimum 140
* Secara angka, komponen PM25 menempati urutan tertinggi walaupun pengukurannya dimulai di tahun 2021 (Penjelasan lengkap akan dibahas di segmen Pengukuran PM2.5)

### Analisis Data dan Visualisasi Setiap Komponen Pencemar
"""

ispuDKI5 = eda_stasiun(ispuDKI5)

"""**Berdasarkan hasil analisis _Missing Value_, _Zero Value_ serta tanggal _Range_ berikut**
* Data dari DKI5 dicatat mulai dari tanggal 27 November 2012 hingga 31 Desember 2021
* Secara total, terdapat 647 Data NaN dimana PM10, SO2, dan O3 merupakan komponen udara yang paling banyak data NaN
* Selain itu, seluruh nilai data > 0 kecuali SO2 dimana terdapat 4 data yang bernilai 0

**Berdasarkan dari diagram PM10 berikut**
* Terjadinya pola _seasional_ dimana ada pola indeks PM10 mengalami kenaikan secara umum di pertengahan tahun dan akan menurun di akhir tahun.
* Meskipun begitu, berdasarkan data di tahun 2012 - 2016, sempat terjadi kenaikan indeks secara besar di sekitaran bulan Febuari dan Maret 2014 dan sekitaran Juni dan Juli 2015.
* Kenaikan tertinggi terjadi di pertengahan tahun 2018 dan sekitaran awal tahun 2019 dimana indeks di awal tahun 2019 sangat dekat dengan level 250
* Indeks PM10 di tahun 2021 berada di posisi paling rendah yaitu dibawah level 50.
* Penurunan indeks PM10 paling dalam terjadi mendekati akhir tahun 2014 hingga awal tahun 2015 dimana indeks turun dari 70-an menjadi dibawah level 20 di awal tahun 2015

**Berdasarkan dari diagram O3 berikut**
* Pola pada data tahun 2013-2015 cukup berfluaktif
* Sejak dari tahun 2015 hingga 2017, peningkatan O3 terjadi menjelang akhir tahun, walaupun di tahun 2015 terjadi peningkatan O3 di sekitar bulan Maret dan April kemudian perlahan menurun
* Berdasarkan data tahun 2018, terjadi peningkatan indeks O3 di pertengahan tahun
* Berdasarkan data tahun 2019, peningkatan terjadi 2 kali, yaitu di awal tahun dan akhir tahun
* Berdasarkan data tahun 2020
  * Peningkatan tertinggi terjadi di akhir bulan Febuari dan berpuncak di tanggal 1 Maret dan mulai menurun sejak pertengahan Maret hingga April
  * Sejak akhir September hingga akhir Oktober, terjadi penurunan yang sangat tajam dimana sebelumnya Indeks berada diatas level 100 kemudian menurun di bawah level 50 dan mendekati level 0 ISPU
  * Peningkatan kembali terjadi di 1 November dan bergerak melewati level 50 ISPU di beberapa hari kedepannya
  * Pergerakan mulai menurun di pertengahan November hingga akhir tahun, namun nilai Indeks tidak serendah seperti di akhir September hingga akhir Oktober

**Berdasarkan dari diagram SO2 berikut**
* Pada tahun 2013 hingga 2014, terjadi sebuah pola dimana sepanjang tahun akan terjadi peningkatan kadar SO2 dan akan menurun secara dalam di bulan November-Desember
* Pola tersebut berubah ketika tahun 2015 dimana indeks SO2 mengalami peningkatan yang pesat sejak April hingga Juni 2015 hingga seterusnya nilai indeks terlihat stagnan hingga akhir tahun
* Pola yang terjadi di tahun 2013 dan 2014 kembali terjadi di tahun 2018 hingga 2020
* Peningkatan indeks SO2 secara tajam terjadi 3 kali, yaitu awal tahun 2018, pertengahan akhir tahun 2018, dan awal pertengahan tahun 2021
* Jika melihat data di antara bulan Mei dan September 2015, terdapat beberapa hari dimana tidak tercatat indeks SO2. Kejadian serupa terjadi di awal pertengahan tahun 2020, sebelum akhirnya nilai indeks sempat naik dan turun, kemudian naik secara perlahan

**Berdasarkan dari diagram NO2 berikut**
* Pergerakan indeks NO2 sejak akhir tahun 2012 hingga 2020, indeks NO2 rata-rata berada di antara 0 hingga 20 ISPU
* Peningkatan indeks yang tajam terjadi di akhir September hingga akhir Oktober 2020 dimana puncak kenaikan berada di pertengahan bulan Oktober
* Berdasarkan data tahun 2021, pergerakan indeks NO2 mengalami fluktuatif dimana peningkatan terbesar terjadi di akhir bulan Juni dan akhir Desember

**Berdasarkan dari diagram CO berikut**
* Sejak akhir 2012 hingga Juli 2013, indeks CO mengalami fluktuatif kemudian bergerak menurun secara besar di bulan Agustus hingga Desember 2013, kemudian meningkat secara tajam di pertengahan Desember hingga turun mendekati awal tahun 2014
* Dari bulan Juli 2014 hingga awal tahun 2016, indeks rata-rata berada di bawah 40 ISPU, kemudian di bulan berikutnya terjadi peningkatan hingga mengalami tren penurunan di pertengahan tahun 2017 hingga awal tahun 2018
* Setelah itu terjadi peningkatan selama beberapa pulan kemudian menurun dan mulai stagnan hingga mulai pertengahan 2019
* Sejak pertengahan 2019 indeks menurun hingga mendekati akhir 2019 dan mulai meningkat hingga awal tahun 2020
* Di tahun 2020, terdapat peningkatan secara tinggi di bulan Oktober dimana indeks melewati zona 120 ISPU

###Analisis Skew dan Kurtosis
"""

eda_skew(ispuDKI5)

"""Berdasarkan histogram berikut, seluruh histogram selain Histogram PM10 dan PM2.5 memiliki distribusi positif dimana _tail_ kanan lebih panjang dibandingkan _tail_ kiri dimanai skor skew rata-rata berada diluar range -0.5 sampai 0.5

## Analisis Komponen PM2.5
"""

ispuDKI1.loc[ispuDKI1.index.year >= 2020, ['pm25']].plot(figsize=(25,10), grid=True, title = "Nilai ISPU PM2.5 DKI1 Tahun 2021", xlabel="Tahun", ylabel="ISPU")
ispuDKI2.loc[ispuDKI2.index.year >= 2020, ['pm25']].plot(figsize=(25,10), grid=True, title = "Nilai ISPU PM2.5 DKI2 Tahun 2021", xlabel="Tahun", ylabel="ISPU")
ispuDKI3.loc[ispuDKI3.index.year >= 2020, ['pm25']].plot(figsize=(25,10), grid=True, title = "Nilai ISPU PM2.5 DKI3 Tahun 2021", xlabel="Tahun", ylabel="ISPU")
ispuDKI4.loc[ispuDKI4.index.year >= 2020, ['pm25']].plot(figsize=(25,10), grid=True, title = "Nilai ISPU PM2.5 DKI4 Tahun 2021", xlabel="Tahun", ylabel="ISPU")
ispuDKI5.loc[ispuDKI5.index.year >= 2020, ['pm25']].plot(figsize=(25,10), grid=True, title = "Nilai ISPU PM2.5 DKI5 Tahun 2021", xlabel="Tahun", ylabel="ISPU")

"""Berdasarkan diagram berikut
* Seluruh stasiun memiliki pola pergerakan yang sama dimana indeks akan bergerak naik hingga mencapai puncaknya di bulan Juli awal.
* Setelah itu indeks akan bergerak turun hingga puncaknya di awal Desember
* Setelah itu indeks akan bergerak naik hingga akhir tahun
* Jika kembali melihat hasil rata-rata dan nilai maksimum PM<sub>2.5</sub> di setiap stasiun, bisa dilihat meskipun data PM<sub>2.5</sub> tidak sebanyak data komponen pencemar lainnya, tapi nilai rata-ratanya paling tinggi dibandingkan dengan komponen pencemar lainnya

Salah satu hal yang menjadi catatan adalah pengukuran PM<sub>2.5</sub> baru mulai tersedia **sejak tahun 2021**. Hal ini disebabkan dikarenakan aturan mengenai pengukuran PM<sub>2.5</sub> baru dikeluarkan di bulan Juli 2020 melalui **Peraturan Menteri Lingkungan Hidup dan Kehutanan Nomor P.14/MENLHK/SETJEN/KUM.1/7/2020**. Sebelumnya aturan mengenai Index Standar Pencemaran Udara merujuk kepada **Keputusan Menteri Negara Lingkungan Hidup Nomor KEP-45/MENLH/10/1997** dimana belum ada aturan pengukuran PM<sub>2.5</sub>.

Ditambah berdasarkan Pasal 11 peraturan menteri terbaru tertulis bahwa penyesuaian penentuan ISPU sesuai dengan ketentuan Peraturan Menteri tersebut paling lambat 2 (dua) tahun sejak berlaku, sehingga sangat wajar jika pengukuran PM<sub>2.5</sub> dilakukan di tahun 2021.

## Exploratory Data Analysis (Missing Value)

Dalam artikel di **_Towards Data Science_** yang berjudul [**4 Techniques to Handle Missing values in Time Series Data**](https://towardsdatascience.com/4-techniques-to-handle-missing-values-in-time-series-data-c3568589b5a8") terdapat 4 teknik yang dapat digunakan untuk mengatasi _Missing Value_ pada data Time Series, yaitu

1. _Last Observation Carried Forward (LOCF)_
2. _Next Observation Carried Backward (NOCB)_
3. _Rolling Statistics_
4. _Interpolation_

Dimana teknik _LOCF_ bekerja dengan mengganti nilai yang hilang dengan nilai sebelumnya, sebaliknya _NOCB_ bekerja dengan menggantikannya dengan nilai berikutnya.

Teknik ini sangat simpel, namun memiliki kelemahan dimana akan kehilangan gambaran pergerakan tren, terutama jika nilai yang hilang cukup banyak.

Selain itu, kelemahan _NOCB_ adalah jika setelah nilai yang hilang tersebut adalah NaN juga, maka nilai yang hilang tersebut akan digantikan dengan NaN.

Selain kedua teknik tersebut, terdapat teknik _Rolling Statistics_ yang bekerja dengan menggantikan nilai yang hilang dengan aggregat nilai sebelumnya sebesar _n_ dimana _n_ ini merupakan jarak atau banyak data yang ingin di aggregatkan.

Ada 3 metode untuk menggunakan metode ini, yaitu

a. _Simple Moving Average_

![Simple Moving Average Formula](https://miro.medium.com/v2/resize:fit:640/format:webp/1*GqcyY6_vA-cvcj90Tg6KdA.png)

_Simple Moving Average (SMA)_ merupakan salah satu metode yang paling simpel dimana nilai data sebelumnya yang sebanyak _n_ akan di jumlahkan dan akan di bagikan dengan _n_. Sederhananya, metode ini bekerja dengan mengganti data yang hilang dengan nilai rata-rata data sebelumnya sebesar _n_-data.

b. _Weighted Moving Average_

![Weighted Moving Average Formula](https://miro.medium.com/v2/resize:fit:720/format:webp/1*6PlxApRuwnKzomxEaN1zjw.png)

_Weighted Moving Average (WMA)_ adalah metode lainnya dimana nilai yang akan di jumlahkan akan diberikan sebuah _weigth_ atau bobot dimana bobot ini di distribusikan secara merata sehingga jumlah keseluruhan bobotnya adalah 1 (100%). Contohnya, jika rata-rata yang ingin diambil adalah rata-rata 5 hari sebelumnya, maka bobotnya adalah: **5/15; 4/15; 3/15; 2/15; 1/15** dimana jika dijumlahkan akan menghasilkan 1.

c. _Exponential Moving Average_

![_Exponential Moving Average Formula](https://miro.medium.com/v2/resize:fit:720/format:webp/1*1tmY0vW2LmgAY4ASIWD-5A.png)

_Exponential Moving Average (EMA)_ adalah metode memiliki kerja yang mirip dengan _WMA_, namun jika di _WMA_ penurunan bobotnya konsisten, penurunan pada _EMA_ bersifat eksponensial dimana nilai _alpha_ merupakan nilai _smoothing factor_ mirip seperti penentuan bobot pada _WMA_.

Teknik _Rolling Statistics_ selain dipakai untuk menggantikan data yang hilang, juga digunakan oleh pelaku _trader_ untuk memprediksi harga aset mereka di pasar.

Selain teknik _Rolling Statistics_ ada juga satu teknik lainnya yaitu _Interpolation_. Teknik ini bekerja dengan dengan menggantikan nilai yang hilang dengan mengasumsikan hubungan dalam rentang titik data. Perbedaan dengan teknik sebelumnya adalah pada teknik _Rolling Statistics_ data yang digunakan hanyalah data masa lalu, sedangkan pada teknik interpolasi, data yang digunakan adalah data masa lalu dan masa depan yang sudah diketahui.

Ada 3 variasi dalam teknik interpolasi, yaitu

a. _linear_

Teknik ini bekerja dengan melakukan asumsi hubungan secara linear lurus antar rentang titik data

![Linear Function Graph](https://upload.wikimedia.org/wikipedia/commons/thumb/d/dd/LinearInterpolation.svg/256px-LinearInterpolation.svg.png)

b. _spline_

Teknik ini bekerja dengan memperkirakan nilai yang meminimalisir kelengkungan sehingga memperoleh lengkungan fungsi yang lebih halus.

![Spline Function Graph](https://upload.wikimedia.org/wikipedia/commons/thumb/5/55/Parametic_Cubic_Spline.svg/350px-Parametic_Cubic_Spline.svg.png)

c. _time_

Teknik ini bekerja dengan memperkirakan nilai yang berfokus pada titik terdekatnya.<br><br>



Pada proyek ini, akan dilakukan penerapan _Spline Interpolation_ dan _time Interpolation_ untuk mengetahui metode mana yang lebih efektif dan dapat meningkatkan akurasi prediksi
"""

def fill_interpolation(df, component, option, order=0):
  df_new = df[['stasiun', component]].copy()
  if (option == 'spline'):
    return df_new.interpolate(method=option, order=order, limit_direction ='backward')
  return df_new.interpolate(method=option)

"""### Spline Interpolation"""

dki1NO2SI = fill_interpolation(ispuDKI1, 'no2', 'spline', 2)
dki2NO2SI = fill_interpolation(ispuDKI2, 'no2', 'spline', 2)
dki3NO2SI = fill_interpolation(ispuDKI3, 'no2', 'spline', 2)
dki4NO2SI = fill_interpolation(ispuDKI4, 'no2', 'spline', 2)
dki5NO2SI = fill_interpolation(ispuDKI5, 'no2', 'spline', 2)

"""### Time Interpolation"""

dki1NO2TI = fill_interpolation(ispuDKI1, 'no2', 'time')
dki2NO2TI = fill_interpolation(ispuDKI2, 'no2', 'time')
dki3NO2TI = fill_interpolation(ispuDKI3, 'no2', 'time')
dki4NO2TI = fill_interpolation(ispuDKI4, 'no2', 'time')
dki5NO2TI = fill_interpolation(ispuDKI5, 'no2', 'time')

"""### Perbandingan (Stasiun DKI 1)"""

eda_line_visualization(ispuDKI1, 'no2', 'Nilai ISPU NO2 DKI 1 (Asli)')
eda_line_visualization(dki1NO2SI, 'no2', 'Nilai ISPU NO2 DKI 1 (Spline Interpolation)')
eda_line_visualization(dki1NO2TI, 'no2', 'Nilai ISPU NO2 DKI 1 (Time Interpolation)')

"""### Perbandingan (Stasiun DKI 2)"""

eda_line_visualization(ispuDKI2, 'no2', 'Nilai ISPU NO2 DKI 2 (Asli)')
eda_line_visualization(dki2NO2SI, 'no2', 'Nilai ISPU NO2 DKI 2 (Spline Interpolation)')
eda_line_visualization(dki2NO2TI, 'no2', 'Nilai ISPU NO2 DKI 2 (Time Interpolation)')

"""### Perbandingan (Stasiun DKI 3)"""

eda_line_visualization(ispuDKI3, 'no2', 'Nilai ISPU NO2 DKI 3 (Asli)')
eda_line_visualization(dki3NO2SI, 'no2', 'Nilai ISPU NO2 DKI 3 (Spline Interpolation)')
eda_line_visualization(dki3NO2TI, 'no2', 'Nilai ISPU NO2 DKI 3 (Time Interpolation)')

"""### Perbandingan (Stasiun DKI 4)"""

eda_line_visualization(ispuDKI4, 'no2', 'Nilai ISPU NO2 DKI 4 (Asli)')
eda_line_visualization(dki4NO2SI, 'no2', 'Nilai ISPU NO2 DKI 4 (Spline Interpolation)')
eda_line_visualization(dki4NO2TI, 'no2', 'Nilai ISPU NO2 DKI 4 (Time Interpolation)')

"""### Perbandingan (Stasiun DKI 5)"""

eda_line_visualization(ispuDKI5, 'no2', 'Nilai ISPU NO2 DKI 5 (Asli)')
eda_line_visualization(dki5NO2SI, 'no2', 'Nilai ISPU NO2 DKI 5 (Spline Interpolation)')
eda_line_visualization(dki5NO2TI, 'no2', 'Nilai ISPU NO2 DKI 5 (Time Interpolation)')

"""### Kesimpulan

Setelah dilakukan perbandingan dan pengecekan, disimpulkan bahwa hasil _time interpolation_ memiliki hasil yang lebih baik dibandingkan _spline interpolation_ dimana hasil interpolasi dari _time interpolation_ tidak melewati batas bawah dari nilai ISPU, yaitu 0 dan pergerakannya tidak setajam dari _spline interpolation_. Sehingga hasil dari _time interpolation_ akan dipakai ke tahap berikutnya

# Exploratory Data Analysis (Analisis dan Normalisasi Skewness dan Kurtosis)

Dalam dunia nyata, data yang akan diterima umumnya tidak memiliki distribusi normal. Hal ini karena sampel tersebut memang tidak berasal dari populasi yang berdistribusi normal. Oleh karena itu, perlu dilakukan pengujian normalitas untuk memastikan apakah data yang sudah dikumpulkan telah memenuhi normalitas data.

Data dikatakan memiliki distribusi normal jika memenuhi ciri-ciri berikut:

1. Bentuk simetris: Distribusi normal memiliki bentuk yang simetris di sekitar nilai tengahnya. Artinya, nilai rata-rata, median, dan modus berada pada posisi yang sama di tengah distribusi.

2. Tidak ada skewness (kemencengan): Distribusi normal tidak memiliki kemencengan yang signifikan. Kemencengan mengindikasikan adanya kecondongan ekor distribusi ke satu sisi. Dalam distribusi normal, ekor distribusi di kedua sisi memiliki kecondongan yang sama.

3. Tidak ada kurtosis ekstrem: Distribusi normal memiliki kurtosis yang moderat. Kurtosis mengukur tingkat keekstreman ekor distribusi. Dalam distribusi normal, kurtosis tidak terlalu tinggi atau rendah, menunjukkan ekor yang tidak terlalu berat atau ringan.

4. Persentil sesuai dengan nilai z: Persentil data dalam distribusi normal sesuai dengan nilai z dalam standar deviasi. Misalnya, 68% data berada dalam satu standar deviasi dari rata-rata, 95% data berada dalam dua standar deviasi, dan 99.7% data berada dalam tiga standar deviasi.

5. Diagram Q-Q: Plot kuantil-kuantil (Q-Q plot) data terhadap kuantil-kuantil dari distribusi normal menghasilkan garis lurus. Ini menunjukkan kesesuaian data dengan distribusi normal.

Dalam proyek ini, akan dilakukan pengujian normalitas data menggunakan pendekatan skewness dan kurtosis.

Skewness dan kurtosis adalah ukuran statistik yang digunakan untuk menggambarkan bentuk distribusi data. Skewness mengukur asimetri dari distribusi data, sedangkan kurtosis mengukur keekstreman (atau bentuk ekor) dari distribusi data.

Skewness mengindikasikan sejauh mana distribusi data condong ke satu sisi. Nilai skewness positif menunjukkan bahwa ekor distribusi data condong ke kanan, sedangkan nilai skewness negatif menunjukkan bahwa ekor distribusi data condong ke kiri. Nilai skewness nol menunjukkan bahwa distribusi data simetris.

Rumus skewness yang umum digunakan adalah:

![skewness formula](https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcQgI0VXs9SvS2SMXUXbfVR0Bj_43i4OL9n39pHaHTeB2hhjEkh2jMqTbbHXzICt7eeVHic&usqp=CAU)

Dimana dalam rumus ini:
*   X mewakili setiap titik data dalma sampel
*   X̄ mewakili rata-rata sampel
*   n mewakili jumlah data dalam sampel
*   S mewakili simpangan baku (standar deviasi) sampel


Sedangkan Kkrtosis mengukur keekstreman (atau bentuk ekor) dari distribusi data. Nilai kurtosis tinggi menunjukkan bahwa distribusi data memiliki ekor yang lebih berat dan puncak yang lebih tajam, sedangkan nilai kurtosis rendah menunjukkan distribusi data dengan ekor yang lebih ringan dan puncak yang lebih datar.

Rumus kurtosis yang umum digunakan adalah:

![kurtosis formula](data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAXMAAACICAMAAAAiRvvOAAACc1BMVEX///8AAAAICAg2Njbw//9wAADDw8MAZazM5P30///x5dCcaQAAKktptvcAS4GfzvoZLoi6////8difglmanqbj5OZaXWPs3LwAAE9/XACdnJz4+PhiZmurjF/G2evY6P+xtLp+zd/EkQAARX1BdrdQAAD/4quF2OV5UwAAGC1dnMzWs6OHi5NbW1v///mtra3g//+ZqbsAADgWEAUAAA4AABr///IvLy//6b5eTTMeAABEAADd9f+uv9QAAEQwAAD/7N/w9v/U///R0dFBRk0/AAAkAAAAAEv//+QAAGHr7OwAACBiAAASAAD7zIw4Wm6+6/8AACzhr3D//97dzMHlv6JqKwCHlqiPYSe7xM9weYOnm3RRS0F2holvdoNrkp6cpZnuz6R2Z5KNa2CSufywiEx5oO3joWwybKWKg42CgZz//ZxTMYldOAAXRF3v55l3SUPJpnhHHAB3a1MpFQAmRWrz7bRSSY6sdleylnw9SWIfICIAIVmdSjJlst7h0ZnOpKNUfdC1telqOgDQ5P/fkl5uTlGCrNtgRgXMk285FAcANmQXMUoAS51NeK5VFgDUrId8Wy5CKBxTm/+8vpCPg66r5+hPi84tLDtXn/GhiUpIfJlEVXmg0+9jOFeDls7/+rCGTTCBMQD/2sKqg4svEVT7tXUALEAOeLG7gUYAC39oQCpQoMszLhpmMxptj93Tr2HR6dgKJYUAX3yDh1E6KgCV1sEAedyHVz+D0/TN0LazhzIALzIzQzeKhHSUWShFXbTYyHw3V5YAM3WYGRWFLjG1m1CpeYZ0aoqGPmwtAB2nhXf9x6NeRi7cx8/MrM6aUwDppcDbAAAP9klEQVR4nO2d+0MTVxbH5xCFGhXbSIgmEWnVggITQBwUBIJBRRB8EESiUOOKUrpW44NCYaWWtggojW2FbdWiG9tdq7a2rvXVqqt9bVtd/6S988q8wwQSxZn5/GKYezMx39w5cx733sEwAwMDAwMDA4PJBu5NK3/W/4fJRbk1JqepqlJqweu3LJwfk8/QCukNjTE5jycl3SHfYtsKhuY8ptibPApSRYmj0WeXPZN72/bVhuYc85t8iiYhatKas1dKjzqyXtuxyNA8zHyfM3aSY1hjqk8iOu7f+VKWoXmYKT7TezE9YXqhM1d0qPIvuzBDcw47ZMf8jD7RkZbdGG5oHiY9ITXWp1yZCimCA3taV2lfc4c8Mj3TKkT6REPl69ksbS/xjqeDie96vvFX1Kh1zf17QY43N0q72hNypo33Y/B9i8LnXsfXPDeVb10q98/CtK85ETgAMJiXzmfHwUOHZ0l6JhZOxJq3789heYuvOZYCCensa3z2bupfjWuOWTqKoGCmaAB3vi3RfFpTQldsAlAhaQngYy3ZngUeij+KW0s8Mq67ZjCvAOjOEB5z/7FL3C3RBKmxCUBFpEJXOvPyb3zzdmTchuw5oAeZ9NYXBIcIm1hzh72LG48xxQcJ2XQWEX/HTrHjYNnhBntaPD5sslC5uQyWHRVcynjVu6JOnlSAhrhongJQITRaeL3G7TlGmnRkXY5M4R8qF39nZFriYs6RQe+CQpfgiNb9Fgp3L8Dhs5F6VGUnQEVs8uZiVlYA+AQlCl1oju0rhmWtkVIppGlJjWV6iwc6dYWHf0AfmhPvA5QuEaebeHjQYBSkFKtc9lHKGhH1zX1q3Dr0hjy6X9YHfYIWJ4ApkX8Az1qdpH3NMfdWFBm9PEWxHQVEwMuc1x8DSADSt8H7ByB5bBejFnVnPqDlEBwXeP8+gMJ0QW9HlS7KoVVbAB4oWpfyBuQwZ/PcFgeWNQAnVmGOPaih++zYrrSDCFyHofkY3oLesFjgiTaB2KDrBHzfh6BchbT6RJojfllamoHv27nRvf+oKkNABMrQBREcym0/ObSK34CcRXDG5/48yXH0r4HSlxVMuhXZXMgTau7/CD4mLsjkwpTw9q490t4mtf2k5qkemTdoH/dsZHEVrIQ1Vap55d8g6RNJiiAC5pMwdGpY+gF5IHZc9INtaw2MyNtVOc2xFpgzFMHVkWCZB3+XO3+JjjUnehYlb1QY5zkymtcWgXSY4+ZEOjfokRh5FNKvk3ONKM0Tpcf1gCP4dp+CAyKreft6+FTSEw1mBmmbLTP/iKE5H9y/f1TJY5O1LT1bIEliWyJojvv3ytouHdsWy2enFZ0QOc3r2j6DF18S9yS8LoYXxE3mbTllcvGlfjV3dJ5RDm0oX1GUys26tRlmSEt4irgfl2R9+J3Mz1qiV18R93++SzmalImJ/KO554oXz0SvpiinDPgfYGvL9R/Lv4U+RDTWdeuf150fipCpomJ/wUzF0Kn3MPwfy+7nYtZGVQ6j2T6MhW6SBv3V3cIWUvNmPcb+LdckpplPIy/HRQSbz1oukIZoOgqi3Cljh6KBM7MIssJaN2/NiVX+naIfNxugK0XVtaIt9nwROaLk53LNcyHhMOVofwlQPTS25O1TYVk3df7gAVjaKr6epHlFXbCvWOpNC/DkcDULoufKYeZ2u7X08qoI72IJrjlD32wtLf/8RmJFnLp0z4nef41hk8vRYKyIU52I/Dn1l1a8+JXEQHhThAM4sRAK4zP7IdcEXa6xu2mMPUUSN5uoHxXe1UiDHp+5FiXi0pweaL90WXLM6xTWLLHy7IQ4zSnK1mHFwr11wbBViMd1aYF46Mdt7pxPf6aF6F+zwSkk5wrAGXG6BIWihfEIFssrIEdnwxz3fy03/7zgtMQHTC+Ehjj8B0ogYfwrCZ5Plm+VnfNfvVCieVUTpMYhWszWoTVPlCdNmvBqrOBm58cMa2EcTqodHCngjPlJU+LkDWkFhw9i7WF4CisMySMyxdkV21h0SpNJy0tYYkKuyRnT26i9oiSWp9MmuTlNMVzm4zIkV4WvKZp5RBFxSRb7jwVeVSWcsusQH4gd8Ttz9KT4YmPTy/Oyo04Om9fDQ35SInQeIF+akZfHEd0VOh3yZ0b1hniyMjYpAE9j9FbKPBWSeZqTknfvVie5w30hI6p70XSYMXk0f4YINackV5wHJQTPOlkaYU2DDNNhk6E5JtKclHxQpeTk/LI50WketKdEXNamF/iaRzPKx6O5AQ1Pc1Lyh32qPQtD8/HCaR46XwMv7lLvzFWSmmt5B4G4EdY8dL4I5vAkv5rKFROXO53UgiVLZ87pcsy7zdlQ8u3+nCtQvcGZw9wVcbP9rvO3hhJ+wtq7Y5vT+VpeOKHa4myepdCkK1jNacl5Da9A9RL29asA35GT0iyzYcG3264shYSK16YydYEbZAe8/eD2LrIw0/V2H2tuQrNNXUvJQxWnmfAj7CuGZm+nm46f1vS+DwowmluQ5KWCgu0rsJjTfCk9Rxtpfu3f10mlF3y/nqc5HvwwXJtZzNTDQjdrwscOZ1DjmdU8dLOIa9LhLYHWfHkHGuXCGrmC5gClSDfiXf49FK8tJsXLxTAb6lB9mcw/VM4rA2prJjywl12yyWheGZA2yUF9mogkSS8rJExqQJpZpzRffo8ckx+r0nztLVaSsOaWLbBpIZNB7l8DM8j7AHKCFjBzZM2Z0E3dbBnN5ZrkqLydImG3pJdVthI6iZDXPK+jpgBZ49Jb/AYlzVvZ2yyn+fvoaHjB9x1Y1or69hyDJKanu7O5YZinubhpYsbF2mWa1HTJav7DjwOQvOMSQDJ/8raS5iMSzfEnaGiHhTu3HgbRvdh/DAaHRY4noznZlDFpEozPADPpfxQczsD8B5Bt5SmhoPmmW6wpCGvePhV4m+o5plPGxX0T4PiIx1rOsxyM5u4OaZOuIDUvuIb8CuJiEeTv5q5zBc3nZEg031cGG7gZsfgrkD+SS41mxJunS5C4TBPrt9ikTXLgVVYJmtgQBWm+7BqVkrWcB3TNh8eees1rga85su75ZABF3D54iLqHbDrT0EhLy2ou0yRH5bZUMTlHY/fNnx1I80FmD0DbAShoDYs3Ic2papXX1bmd1nawgfJquPy51dWZQzd1NyiWzAmvXYImKo/8vOLVNbBplJUAxaEjrLxR2ZY7UDrCVAgJT6Lr7nYUcc6gUmf8mkW4abH6rJpW4GtuuYeGJLuWHWl+ny2u1kbUXHIP7ebP+q7yZKGwk1o5LK4T8Zp0haBmYUZx4TVmyH7J0/xqRM2JJzDIbWvQTvuKVpc9XJ+o3wvUshNGc7JpGq9JxZ5M2kKgOf6f1VAwRI+7L2HZA8Zfr0TjP4LmVEwUnuj9CxQkb8SIzoGaETYasGXCQ05zonN1TdjJt82lm3SFsB7qvoiC+yWUSa8to4N4RGBAUXPqDxT757Oxf3A1/TY0gNcx5yUCxXCfZ1v4TT2L6CZdIar7mzPDDiN6dZzMW3lnH/qhTEbzypYiuDZMvsI3lyG3j9yoxjKvBo15smvd7BpY20caJ0fnXqCL1YzmdeiNa5esEjTpCpHmRE8xQDI18mpXs1ma0u9/ktGcCBaTjWSmD+8v43I6rbRFCvFWPmw6ys8rUkVAUZOuEGmOufvRSKW3V67dm0CqkjCYgf8UrllwmqMYnkyDUz8G3rOC6gsJ3VzNouUQc+w4sxEcV7Pgmo7EbA7bJERhgrT5Z1OrIHFunm3a/gUjbNbdFRU+5JLgP5uo+6ml0/SQ0xxzZ31g2v4dPawJ790c04bmPr6EXvtdU8XbTSWsy3/HtGGmQpMWqftlUI9VsGcJHhxQsR2sQSzxPlpqaP50sf3aNHeBofnThNg2ejvT0PypktW20mZo/lQJNW/EDM2fKu2/zppmaB5nQjsOpvryyJA6ROZAWnZPw/SheedEMpR4Tx+ThcBt0c6Sr9v2+elhq9Vj71tZSW5lF1xIBo460Lz+t4j7/EUG9x88lMTmoy3B0aiSQHUtRTfoF4GPrrSuxF6ln/+nfc2DrePP3OD+R2S2LlwDID75TbJPbgQCAw+Zn9vSUXO0vP2/9F82rfvngYlIXjeLzPFzmmOVVyM/XErA8kv05GSS+gNHpmzmz5y7od1qb2BdxtidImHL5GuOWS6qH6OB65zmtrfOTrt6pZBmaUHXFYVHDmiA+gMT/W62uQLNMVuv6vrV1euQxCZbQ23cT2XLTNZw2dG29auMCRayxZoTgd/ldvOXo3YvzGGvsj/f5X4pTd9D8eDAhJ/sJtYc8x97qPI+uvwmQDLTN5TGXW+a1jx0r5o3JqusnkaqQONJbFRfEpFojpQcUXftEP0DADIlRi1rjgcPzGHnyDi8rrs528lRb3GtKNp0WrXLJ9Gc6ChTOwuEnGhc/Y1EdFvmQ81qbmmBB6xcDm9i53VYUo6F/mhzdcCg6qcmSDRH7kiB2pXy5pPkxhTii8rtLdGs0+LthSTec/1sx9a+PC10oWQlvjk8Q2ds5DSHG2pvzLZegNJRLRd3heD+RfyFYCi6efBC3etp0zB8D0j2blVEqvmfl+ArcTahs61E3pmxbSEfjKzlOQwCiADAEm6IWTpg6Nt3SPvumC7du1URqeb+R5AvCrQCS+GMwq+4rxjgTd1Mj3L3A1zmNLdllh7ZMUyOuHPrN6l/kpxU8+UrAEQGfTooWiticxl/JZvGcV/kP70Sr1+UvINOC+6hJgirRF5z0bMa7oDyKfGLyKTrxbogzddymqNR/+MQ7aJN560aYToyyDz2QpXmjpNrL4tUfdzI2hN3pn4GOiklZ1vMc9lZp28sqhY+j3vimsvwv/BNFd9TA0lRPNHreUZoz71bYCE92N4X2wF3fyG9TPaKjH1QZc+l1L0Tnp+J29YLp35qGCJQxPktxOai7rO0Ck8KHkRROJLVPP+WQu8w7l+5rIN3PQxFU+p4jhH458h+MN/7XPHikShcNxn//JHUP5e+7XzYwOO2Rflia69ZvJlcHGrrncMMPGRaZuFVqlWX8c+vw4kxJbRtCacdiKtFybrZ4s3cAuxkTKK2jFnChz+BE6u8JRPwzzeryLcQgbJqdmyHekv79BITYUTwAPuEZvxOAfPkuPapcKJR/fR2vH6vcD9Vcu3Ii2PmFd2dba7shvfID/feG+zT0ZIRLn9unpq/hH5V11t9ZlitBu4Ld8nC/+HsU9x2YnUdNWPnz92ujVhVYp7Lnt3gG03TbBZRBryTrRMRj8NlCm+jVfWVjj9mnn/Bs0X+Yw/Hts4OK/mzVHkSExsjbhehQWJQDxWDB36/rBvrPB7w+q8/jfEwC229r5M4ftwEvxgzfIkKIhDFpCK9EkiewGxFKTan7nYhGAfBaCL9sfA2G6NcDf6dsRIdv33KsOUq6YzN4MTrSwy7YmBgYGBgYGBgYGBgYGBgME7+D/f1dhm/wNsrAAAAAElFTkSuQmCC)

Dimana dalam rumus ini memiliki arti yang sama dengan rumus skewness.

Sebuah distribusi data dinyatakan normal jika memenuhi aspek berikut:
1. Jika skewness berkisar antara -0,5 hingga 0,5, data dapat dianggap mendekati distribusi normal.
2. Jika kurtosis berkisar antara -2 hingga 2 (atau antara 2 hingga 3 jika menggunakan definisi kurtosis ekscess), data dapat dianggap mendekati distribusi normal.

![skewness categorical](https://upload.wikimedia.org/wikipedia/commons/thumb/c/cc/Relationship_between_mean_and_median_under_different_skewness.png/600px-Relationship_between_mean_and_median_under_different_skewness.png)

Jika suatu distribusi data tidak memenuhi kriteria berikut, dapat dilakukan langkah normalisasi. Ada 2 teknik yang umum digunakan dalam melakukan normalisasi skewness dan kurtosis:
1. Logaritmik
  * Normalisasi menggunakan logaritma dapat digunakan untuk mengubah distribusi data yang umumnya condong ke kanan menjadi lebih simetris. Pendekatan ini berguna ketika terdapat perbedaan variabilitas yang besar di antara nilai-nilai data.
  * Rumus normalisasi logaritmik:
X
′
 =log(X)

2. Box-Cox

  * Metode normalisasi Box-Cox adalah transformasi yang memperhitungkan skewness dan kurtosis data asli. Transformasi ini menggunakan parameter lambda (λ) yang ditentukan secara otomatis untuk menghasilkan distribusi yang lebih simetris.
  * Rumus normalisasi Box-Cox:

  ![box-cox formula](https://www.leansigmacorporation.com/wp/wp-content/uploads/2016/01/Box-Cox-EQ1.png)

  * Dimana dalam rumus ini
    * X adalah data asli.
    * λ adalah parameter Box-Cox yang ditentukan secara otomatis untuk mencapai distribusi yang lebih simetris.
  * Selain itu x akan di logaritmik jika lambda adalah 0

### Create Skew Normalize Function
"""

def skew_normalize(df, component, method):
  try:
    df_new = df.copy()
    if (method == 'log'):
      df_new[component] = np.log(df_new[component])
    elif (method == 'boxcox'):
      df_new[component], filter_lambda = stats.boxcox(df_new[component])
    return df_new
  except:
    traceback.print_exc()

"""### Logarithm Normalization"""

dki1NO2TI_logNorm = skew_normalize(dki1NO2TI, 'no2', 'log')
dki2NO2TI_logNorm = skew_normalize(dki2NO2TI, 'no2', 'log')
dki3NO2TI_logNorm = skew_normalize(dki3NO2TI, 'no2', 'log')
dki4NO2TI_logNorm = skew_normalize(dki4NO2TI, 'no2', 'log')
dki5NO2TI_logNorm = skew_normalize(dki5NO2TI, 'no2', 'log')

"""### Box-Cox Normalization"""

dki1NO2TI_boxCoxNorm = skew_normalize(dki1NO2TI, 'no2', 'boxcox')
dki2NO2TI_boxCoxNorm = skew_normalize(dki2NO2TI, 'no2', 'boxcox')
dki3NO2TI_boxCoxNorm = skew_normalize(dki3NO2TI, 'no2', 'boxcox')
dki4NO2TI_boxCoxNorm = skew_normalize(dki4NO2TI, 'no2', 'boxcox')
dki5NO2TI_boxCoxNorm = skew_normalize(dki5NO2TI, 'no2', 'boxcox')

"""### Perbandingan (Stasiun DKI 1)"""

eda_skew(dki1NO2TI, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 1 (Asli)')
eda_skew(dki1NO2TI_logNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 1 (Log Norm)')
eda_skew(dki1NO2TI_boxCoxNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 1 (Box-Cox Norm)')

"""### Perbandingan (Stasiun DKI 2)"""

eda_skew(dki2NO2TI, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 2 (Asli)')
eda_skew(dki2NO2TI_logNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 2 (Log Norm)')
eda_skew(dki2NO2TI_boxCoxNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 2 (Box-Cox Norm)')

"""### Perbandingan (Stasiun DKI 3)"""

eda_skew(dki3NO2TI, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 3 (Asli)')
eda_skew(dki3NO2TI_logNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 3 (Log Norm)')
eda_skew(dki3NO2TI_boxCoxNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 3 (Box-Cox Norm)')

"""### Perbandingan (Stasiun DKI 4)"""

eda_skew(dki4NO2TI, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 4 (Asli)')
eda_skew(dki4NO2TI_logNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 4 (Log Norm)')
eda_skew(dki4NO2TI_boxCoxNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 4 (Box-Cox Norm)')

"""### Perbandingan (Stasiun DKI 5)"""

eda_skew(dki5NO2TI, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 5 (Asli)')
eda_skew(dki5NO2TI_logNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 5 (Log Norm)')
eda_skew(dki5NO2TI_boxCoxNorm, 'no2', 'Histori Distribusi Nilai ISPU NO2 DKI 5 (Box-Cox Norm)')

"""### Kesimpulan

Berdasarkan hasil berikut, hasil normalisasi dari Box-Cox memberikan hasil rata-rata **11.43%** lebih baik dibandingkan metode Logaritma. Untuk itu hasil dari normalisasi Box-Cox akan dipakai di tahap berikutnya

# Exploratory Data Analysis (Stasioneritas)

Data stasioner adalah data yang menunjukan mean, varian, dan autovarians tetap sama pada waktu kapan saja data itu dibentuk atau dipakai, artinya dengan data yang stasioner model time series dapat dikatakan lebih stabil. Apabila data yang digunakan dalam model ada yang tidak stasioner.

Pengujian data stasioner umumnya menggunakan metode _Augmented Dickey-Fuller (ADF)_.

Pengujian ADF adalah metode statistik yang digunakan untuk menguji apakah suatu deret waktu stasioner atau tidak. Deret waktu stasioner tidak memiliki tren atau pola sistematis yang berubah seiring waktu.

Rumus pengujian ADF (Augmented Dickey-Fuller) dapat dinyatakan sebagai berikut:

Δyt = α + βt + γyt-1 + δ1Δyt-1 + δ2Δyt-2 + ... + δp-1Δyt-p+1 + εt

Di dalam rumus tersebut:
* Δyt adalah selisih atau differencing pertama dari deret waktu yang diuji.
* α adalah konstanta.
* βt adalah komponen linear yang mewakili tren waktu.
* yt-1 adalah nilai lag satu dari deret waktu.
* Δy
t−1
​
 ,Δy
t−2
​
 ,…,Δy
t−p+1
​
  adalah differencing pertama dari lag-lag sebelumnya.
* γ,δ
1
​
 ,δ
2
​
 ,…,δ
p−1
​
  adalah koefisien yang diestimasi dalam model.
* ε
t
​
  adalah residual atau kesalahan pada waktu t.

Untuk nilai tingkat signifikasi _p-value_ pada ADF adalah 0.05 dimana

_H0_ : _p-value_ >= 0.05 (Tidak Stasioner)

_H1_ : _p-value_ < 0.05 (Stasioner)

Sedangkan untuk KPSS

_H0_ : _p-value_ >= 0.05 (Stasioner)

_H1_ : _p-value_ < 0.05 (Tidak Stasioner)

## Membuat fungsi uji stasioneritas (ADF dan KPSS)
"""

def adf_test(series):
    result = adfuller(series)
    print('ADF Statistic:', result[0])
    print('p-value:', result[1])
    print('lags:', result[2])
    print('Critical Values:')
    for key, value in result[4].items():
        print("\t{}: {} - The data is {} stationary with {}% confidence"
        .format(key, value, "not" if value<result[0] else "", 100-int(key[:-1])))
    print("\n\n")

def kpss_test(timeseries):
    print("Results of KPSS Test:")
    kpsstest = kpss(timeseries, regression="c", nlags="auto")
    kpss_output = pd.Series(
        kpsstest[0:3], index=["Test Statistic", "p-value", "Lags Used"]
    )
    for key, value in kpsstest[3].items():
        kpss_output["Critical Value (%s)" % key] = value
    print(kpss_output)

print("Stasioner DKI 1")
adf_test(dki1NO2TI_boxCoxNorm['no2'])
kpss_test(dki1NO2TI_boxCoxNorm['no2'])

print("Stasioner DKI 2")
adf_test(dki2NO2TI_boxCoxNorm['no2'])
kpss_test(dki2NO2TI_boxCoxNorm['no2'])

print("Stasioner DKI 3")
adf_test(dki3NO2TI_boxCoxNorm['no2'])
kpss_test(dki3NO2TI_boxCoxNorm['no2'])

print("Stasioner DKI 4")
adf_test(dki4NO2TI_boxCoxNorm['no2'])
kpss_test(dki4NO2TI_boxCoxNorm['no2'])

print("Stasioner DKI 5")
adf_test(dki5NO2TI_boxCoxNorm['no2'])
kpss_test(dki5NO2TI_boxCoxNorm['no2'])

"""Berdasarkan hasil pengujian, nilai _p-value_ ADF dan KPSS seluruh stasiun berada dibawah 0.05, sehingga seluruh data stasiun merupakan _difference stationary_ sehingga seluruh data stasiun harus dilakukan differensiasi agar data menjadi stasioner

## Differencing Series
"""

dki1NO2TI_boxCoxNorm['no2_diff'] = dki1NO2TI_boxCoxNorm.no2.diff(8)
dki2NO2TI_boxCoxNorm['no2_diff'] = dki2NO2TI_boxCoxNorm.no2.diff(7)
dki3NO2TI_boxCoxNorm['no2_diff'] = dki3NO2TI_boxCoxNorm.no2.diff(7)
dki4NO2TI_boxCoxNorm['no2_diff'] = dki4NO2TI_boxCoxNorm.no2.diff(7)
dki5NO2TI_boxCoxNorm['no2_diff'] = dki5NO2TI_boxCoxNorm.no2.diff(7)
dki1NO2TI_boxCoxNorm = dki1NO2TI_boxCoxNorm.dropna()
dki2NO2TI_boxCoxNorm = dki2NO2TI_boxCoxNorm.dropna()
dki3NO2TI_boxCoxNorm = dki3NO2TI_boxCoxNorm.dropna()
dki4NO2TI_boxCoxNorm = dki4NO2TI_boxCoxNorm.dropna()
dki5NO2TI_boxCoxNorm = dki5NO2TI_boxCoxNorm.dropna()

print("Stasioner DKI 1")
adf_test(dki1NO2TI_boxCoxNorm['no2_diff'])
kpss_test(dki1NO2TI_boxCoxNorm['no2_diff'])

print("Stasioner DKI 2")
adf_test(dki2NO2TI_boxCoxNorm['no2_diff'])
kpss_test(dki2NO2TI_boxCoxNorm['no2_diff'])

print("Stasioner DKI 3")
adf_test(dki3NO2TI_boxCoxNorm['no2_diff'])
kpss_test(dki3NO2TI_boxCoxNorm['no2_diff'])

print("Stasioner DKI 4")
adf_test(dki4NO2TI_boxCoxNorm['no2_diff'])
kpss_test(dki4NO2TI_boxCoxNorm['no2_diff'])

print("Stasioner DKI 5")
adf_test(dki5NO2TI_boxCoxNorm['no2_diff'])
kpss_test(dki5NO2TI_boxCoxNorm['no2_diff'])

"""## Korelasi (ACF and P-ACF)

Korelasi ACF (Autocorrelation Function) dan PACF (Partial Autocorrelation Function) adalah alat statistik yang digunakan dalam analisis deret waktu untuk memahami ketergantungan atau hubungan antara nilai-nilai dalam deret waktu.
"""

def create_acf_pacf(station, component, lags):
  fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16,5))
  plot_acf(station[component], lags=lags, ax=ax1)
  plot_pacf(station[component], lags=lags, method='ols', ax=ax2)
  plt.show()
  plt.close()

"""### Stasiun DKI 1"""

create_acf_pacf(dki1NO2TI_boxCoxNorm, 'no2_diff', 25)

"""### Stasiun DKI 2"""

create_acf_pacf(dki2NO2TI_boxCoxNorm, 'no2_diff', 25)

"""### Stasiun DKI 3"""

create_acf_pacf(dki3NO2TI_boxCoxNorm, 'no2_diff', 25)

"""### Stasiun DKI 4"""

create_acf_pacf(dki4NO2TI_boxCoxNorm, 'no2_diff', 25)

"""### Stasiun DKI 5"""

create_acf_pacf(dki5NO2TI_boxCoxNorm, 'no2_diff', 25)

"""# Data Preparation

## Train-test Split

Langkah awal untuk membangun model adalah dengan melakukan pembagian antara data latih dengan data pengujian. Untuk proyek ini, pembagian akan menggunakan rasio **80:20** untuk ARIMA dan **60:20:20** untuk LSTM dimana 20% tambahan digunakan untuk data validasi

### Buat fungsi train-test split
"""

def train_test_split(df, column, test_ratio, validation=False):
  if ('tanggal' not in df.columns):
    df.reset_index(inplace=True)
  train_split = int(len(df) * (1 - test_ratio))
  test_split = int(len(df) * test_ratio)

  # Create the train and test sets.
  train_df = df.loc[:(train_split - test_split) if validation else train_split]
  if (validation):
    val_df = df.loc[(train_split - test_split):train_split-1]
    test_df = df.loc[train_split:]
    return train_df, val_df, test_df
  else:
    test_df = df.loc[train_split:]
    return train_df, test_df

"""### Split For ARIMA"""

trainDKI1ARIMA, testDKI1ARIMA = train_test_split(dki1NO2TI_boxCoxNorm, 'no2_diff', 0.2)
trainDKI2ARIMA, testDKI2ARIMA = train_test_split(dki2NO2TI_boxCoxNorm, 'no2_diff', 0.2)
trainDKI3ARIMA, testDKI3ARIMA = train_test_split(dki3NO2TI_boxCoxNorm, 'no2_diff', 0.2)
trainDKI4ARIMA, testDKI4ARIMA = train_test_split(dki4NO2TI_boxCoxNorm, 'no2_diff', 0.2)
trainDKI5ARIMA, testDKI5ARIMA = train_test_split(dki5NO2TI_boxCoxNorm, 'no2_diff', 0.2)

print(len(trainDKI1ARIMA), len(testDKI1ARIMA))
print(len(trainDKI2ARIMA), len(testDKI2ARIMA))
print(len(trainDKI3ARIMA), len(testDKI3ARIMA))
print(len(trainDKI4ARIMA), len(testDKI4ARIMA))
print(len(trainDKI5ARIMA), len(testDKI5ARIMA))

"""### Split For LSTM"""

trainDKI1LSTM, valDKI1LSTM, testDKI1LSTM = train_test_split(dki1NO2TI_boxCoxNorm, 'no2_diff', 0.2, True)
trainDKI2LSTM, valDKI2LSTM, testDKI2LSTM = train_test_split(dki2NO2TI_boxCoxNorm, 'no2_diff', 0.2, True)
trainDKI3LSTM, valDKI3LSTM, testDKI3LSTM = train_test_split(dki3NO2TI_boxCoxNorm, 'no2_diff', 0.2, True)
trainDKI4LSTM, valDKI4LSTM, testDKI4LSTM = train_test_split(dki4NO2TI_boxCoxNorm, 'no2_diff', 0.2, True)
trainDKI5LSTM, valDKI5LSTM, testDKI5LSTM = train_test_split(dki5NO2TI_boxCoxNorm, 'no2_diff', 0.2, True)

print(len(trainDKI1LSTM), len(valDKI1LSTM), len(testDKI1LSTM))
print(len(trainDKI2LSTM), len(valDKI2LSTM), len(testDKI2LSTM))
print(len(trainDKI3LSTM), len(valDKI3LSTM), len(testDKI3LSTM))
print(len(trainDKI4LSTM), len(valDKI4LSTM), len(testDKI4LSTM))
print(len(trainDKI5LSTM), len(valDKI5LSTM), len(testDKI5LSTM))

"""## Windowed Dataset

### Buat Fungsi
"""

def windowed_dataset(series, batch_size, n_past=10, n_future=10, shift=1):
    ds = tf.data.Dataset.from_tensor_slices(series)
    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)
    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))
    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))
    return ds.batch(batch_size).prefetch(1)

"""### Buat Windowed Dataset"""

dki1_train_set = windowed_dataset(trainDKI1LSTM['no2_diff'].values, 32, 7, 7)
dki1_val_set = windowed_dataset(valDKI1LSTM['no2_diff'].values, 32, 7, 7)

dki2_train_set = windowed_dataset(trainDKI2LSTM['no2_diff'].values, 32, 7, 7)
dki2_val_set = windowed_dataset(valDKI2LSTM['no2_diff'].values, 32, 7, 7)

dki3_train_set = windowed_dataset(trainDKI3LSTM['no2_diff'].values, 32, 7, 7)
dki3_val_set = windowed_dataset(valDKI3LSTM['no2_diff'].values, 32, 7, 7)

dki4_train_set = windowed_dataset(trainDKI4LSTM['no2_diff'].values, 32, 7, 7)
dki4_val_set = windowed_dataset(valDKI4LSTM['no2_diff'].values, 32, 7, 7)

dki5_train_set = windowed_dataset(trainDKI5LSTM['no2_diff'].values, 32, 7, 7)
dki5_val_set = windowed_dataset(valDKI5LSTM['no2_diff'].values, 32, 7, 7)

"""# Modelling

Setelah melakukan persiapan pada data, langkah selanjutnya adalah membangun model prediksi.

## ARIMA (Autoregressive Integrated Moving Average)

ARIMA (Autoregressive Integrated Moving Average) adalah suatu model yang digunakan untuk menganalisis dan meramalkan deret waktu, seperti data penjualan bulanan, harga saham, atau suhu harian. Model ARIMA memperhitungkan pola dan tren dalam data untuk membuat perkiraan tentang nilai-nilai di masa depan.

ARIMA terdiri dari tiga komponen utama:

1. Autoregresi (AR): Komponen ini memperhitungkan bagaimana nilai-nilai sebelumnya dalam deret waktu mempengaruhi nilai saat ini. Misalnya, jika penjualan bulan lalu tinggi, kemungkinan penjualan bulan ini juga akan tinggi.
2. Integrasi (I): Komponen ini digunakan untuk membuat deret waktu menjadi lebih stabil dengan menghilangkan tren atau fluktuasi sistematis. Dengan cara ini, kita dapat melihat pola yang lebih jelas dalam data.
3. Moving Average (MA): Komponen ini memperhitungkan pola kesalahan atau perbedaan antara nilai sebenarnya dan nilai yang diprediksi. Dalam model MA, kesalahan masa lalu digunakan untuk memprediksi kesalahan di masa depan.

Dalam model ARIMA, kita menentukan tiga angka dalam format ARIMA(p, d, q), di mana:

* p adalah jumlah lag yang diperhitungkan dalam komponen autoregresi. Semakin besar nilai p, semakin jauh ke belakang kita melihat untuk memprediksi nilai saat ini.
* d adalah jumlah differencing yang dilakukan pada data. Ini membantu menghilangkan tren dan membuat deret waktu menjadi lebih stasioner.
* q adalah jumlah lag yang diperhitungkan dalam komponen moving average. Semakin besar nilai q, semakin banyak kesalahan masa lalu yang diperhitungkan untuk memprediksi kesalahan di masa depan.

## Create and Train Model

### ARIMA

#### Create models and train it
"""

dki1_arima_model405 = sm.tsa.ARIMA(trainDKI1ARIMA['no2_diff'], order=(4, 0, 5)).fit()
dki2_arima_model405 = sm.tsa.ARIMA(trainDKI2ARIMA['no2_diff'], order=(4, 0, 5)).fit()
dki3_arima_model405 = sm.tsa.ARIMA(trainDKI3ARIMA['no2_diff'], order=(4, 0, 5)).fit()
dki4_arima_model405 = sm.tsa.ARIMA(trainDKI4ARIMA['no2_diff'], order=(4, 0, 5)).fit()
dki5_arima_model405 = sm.tsa.ARIMA(trainDKI5ARIMA['no2_diff'], order=(4, 0, 5)).fit()
print(dki1_arima_model405.summary())
print(dki2_arima_model405.summary())
print(dki3_arima_model405.summary())
print(dki4_arima_model405.summary())
print(dki5_arima_model405.summary())

dki1_arima_model = sm.tsa.ARIMA(trainDKI1ARIMA['no2_diff'], order=(5, 0, 5)).fit()
dki2_arima_model = sm.tsa.ARIMA(trainDKI2ARIMA['no2_diff'], order=(5, 0, 5)).fit()
dki3_arima_model = sm.tsa.ARIMA(trainDKI3ARIMA['no2_diff'], order=(5, 0, 5)).fit()
dki4_arima_model = sm.tsa.ARIMA(trainDKI4ARIMA['no2_diff'], order=(5, 0, 5)).fit()
dki5_arima_model = sm.tsa.ARIMA(trainDKI5ARIMA['no2_diff'], order=(5, 0, 5)).fit()
print(dki1_arima_model.summary())
print(dki2_arima_model.summary())
print(dki3_arima_model.summary())
print(dki4_arima_model.summary())
print(dki5_arima_model.summary())

"""### LSTM

#### Create model and compile
"""

dki1_lstm_model = Sequential([
    Input(shape=(7, 1)),
    Bidirectional(LSTM(128, return_sequences=True)),
    LSTM(64, return_sequences=True),
    Dense(30, activation='relu'),
    Dense(10, activation='relu'),
    Dense(1)
])

dki1_lstm_model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=tf.keras.optimizers.RMSprop(0.0001),
    metrics=['mae']
)

dki2_lstm_model = Sequential([
    Input(shape=(7, 1)),
    Bidirectional(LSTM(128, return_sequences=True)),
    LSTM(64, return_sequences=True),
    Dense(30, activation='relu'),
    Dense(10, activation='relu'),
    Dense(1)
])

dki2_lstm_model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=tf.keras.optimizers.RMSprop(0.0001),
    metrics=['mae']
)

dki3_lstm_model = Sequential([
    Input(shape=(7, 1)),
    Bidirectional(LSTM(128, return_sequences=True)),
    LSTM(64, return_sequences=True),
    Dense(30, activation='relu'),
    Dense(10, activation='relu'),
    Dense(1)
])

dki3_lstm_model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=tf.keras.optimizers.RMSprop(0.0001),
    metrics=['mae']
)

dki4_lstm_model = Sequential([
    Input(shape=(7, 1)),
    Bidirectional(LSTM(128, return_sequences=True)),
    LSTM(64, return_sequences=True),
    Dense(30, activation='relu'),
    Dense(10, activation='relu'),
    Dense(1)
])

dki4_lstm_model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=tf.keras.optimizers.RMSprop(0.0001),
    metrics=['mae']
)

dki5_lstm_model = Sequential([
    Input(shape=(7, 1)),
    Bidirectional(LSTM(128, return_sequences=True)),
    LSTM(64, return_sequences=True),
    Dense(30, activation='relu'),
    Dense(10, activation='relu'),
    Dense(1)
])

dki5_lstm_model.compile(
    loss=tf.keras.losses.Huber(),
    optimizer=tf.keras.optimizers.RMSprop(0.0001),
    metrics=['mae']
)

dki1_lstm_model.summary()

"""#### Create Callback"""

def create_callback(filepath):
  return [
      tf.keras.callbacks.EarlyStopping(
          patience=50,
          restore_best_weights=True
      ),
      tf.keras.callbacks.ModelCheckpoint(filepath, 'val_mae', 1, True),
  ]

"""#### Training"""

print("Training DKI 1 Model")
dki1_history = dki1_lstm_model.fit(
    dki1_train_set, epochs=300,
    validation_data=dki1_val_set,
    callbacks=create_callback('/content/dki1_lstm.h5'),
    verbose=2
)

print("Training DKI 2 Model")
dki2_history = dki2_lstm_model.fit(
    dki2_train_set, epochs=300,
    validation_data=dki2_val_set,
    callbacks=create_callback('/content/dki2_lstm.h5'),
    verbose=2
)

print("Training DKI 3 Model")
dki3_history = dki3_lstm_model.fit(
    dki3_train_set, epochs=300,
    validation_data=dki3_val_set,
    callbacks=create_callback('/content/dki3_lstm.h5'),
    verbose=2
)

print("Training DKI 4 Model")
dki4_history = dki4_lstm_model.fit(
    dki4_train_set, epochs=300,
    validation_data=dki4_val_set,
    callbacks=create_callback('/content/dki4_lstm.h5'),
    verbose=2
)

print("Training DKI 5 Model")
dki5_history = dki5_lstm_model.fit(
    dki5_train_set, epochs=300,
    validation_data=dki5_val_set,
    callbacks=create_callback('/content/dki5_lstm.h5'),
    verbose=2
)

"""#Evaluation

Untuk pengujian akan menggunkan 3 metrik evaluasi, yaitu _Mean Average Error (MAE)_, _Mean Square Error (MSE)_ dan _Root Mean Square Error (RMSE)_.

1. _Mean Absolute Error (MAE)_

  MAE adalah metrik evaluasi yang mengukur rata-rata kesalahan absolut antara nilai-nilai aktual dan nilai-nilai yang diprediksi. MAE memberikan gambaran tentang sejauh mana nilai prediksi secara keseluruhan berbeda dari nilai aktual.

  Rumus yang digunakan adalah

  MAE = (1/n) * Σ|i=1 to n| |yi - ŷi|

  Dimana dalam rumus berikut
  * yi adalah nilai aktual
  * ŷi adalah nilai prediksi
  * n adalah jumlah sampel

2. _Mean Square Error (MSE)_

  MSE adalah metrik evaluasi yang mengukur rata-rata dari kuadrat kesalahan antara nilai-nilai aktual dan nilai-nilai yang diprediksi. MSE memberikan informasi tentang variabilitas atau dispersi kesalahan prediksi.

  Rumus yang digunakan adalah

  MSE = (1/n) * Σ|i=1 to n| (yi - ŷi)^2

  Dimana dalam rumus berikut
  * yi adalah nilai aktual
  * ŷi adalah nilai prediksi
  * n adalah jumlah sampel

3. _Root Mean Square Error (RMSE)_

  RMSE adalah akar kuadrat dari MSE dan merupakan metrik evaluasi yang umum digunakan dalam analisis prediksi. RMSE memberikan indikasi rata-rata kesalahan prediksi dalam satuan yang sama dengan variabel yang diukur.

  Rumus yang digunakan adalah

  RMSE = √((1/n) * Σ|i=1 to n| (yi - ŷi)^2)

  Dimana dalam rumus berikut
  * yi adalah nilai aktual
  * ŷi adalah nilai prediksi
  * n adalah jumlah sampel

## ARIMA
"""

print("DKI 1")
predictions_dki1 = dki1_arima_model405.predict(start=testDKI1ARIMA.index[0], end=testDKI1ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI1ARIMA["no2_diff"], predictions_dki1))
print("MSE:", mean_squared_error(testDKI1ARIMA["no2_diff"], predictions_dki1))
print("RMSE:", math.sqrt(mean_squared_error(testDKI1ARIMA["no2_diff"], predictions_dki1)), end="\n\n")

print("DKI 2")
predictions_dki2 = dki2_arima_model405.predict(start=testDKI2ARIMA.index[0], end=testDKI2ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI2ARIMA["no2_diff"], predictions_dki2))
print("MSE:", mean_squared_error(testDKI2ARIMA["no2_diff"], predictions_dki2))
print("RMSE:", math.sqrt(mean_squared_error(testDKI2ARIMA["no2_diff"], predictions_dki2)), end="\n\n")

print("DKI 3")
predictions_dki3 = dki3_arima_model405.predict(start=testDKI3ARIMA.index[0], end=testDKI3ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI3ARIMA["no2_diff"], predictions_dki3))
print("MSE:", mean_squared_error(testDKI3ARIMA["no2_diff"], predictions_dki3))
print("RMSE:", math.sqrt(mean_squared_error(testDKI3ARIMA["no2_diff"], predictions_dki3)), end="\n\n")

print("DKI 4")
predictions_dki4 = dki4_arima_model405.predict(start=testDKI4ARIMA.index[0], end=testDKI4ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI4ARIMA["no2_diff"], predictions_dki4))
print("MSE:", mean_squared_error(testDKI4ARIMA["no2_diff"], predictions_dki4))
print("RMSE:", math.sqrt(mean_squared_error(testDKI4ARIMA["no2_diff"], predictions_dki4)), end="\n\n")

print("DKI 5")
predictions_dki5 = dki5_arima_model405.predict(start=testDKI5ARIMA.index[0], end=testDKI5ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI5ARIMA["no2_diff"], predictions_dki5))
print("MSE:", mean_squared_error(testDKI5ARIMA["no2_diff"], predictions_dki5))
print("RMSE:", math.sqrt(mean_squared_error(testDKI5ARIMA["no2_diff"], predictions_dki5)), end="\n\n")

print("DKI 1")
predictions_dki1 = dki1_arima_model.predict(start=testDKI1ARIMA.index[0], end=testDKI1ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI1ARIMA["no2_diff"], predictions_dki1))
print("MSE:", mean_squared_error(testDKI1ARIMA["no2_diff"], predictions_dki1))
print("RMSE:", math.sqrt(mean_squared_error(testDKI1ARIMA["no2_diff"], predictions_dki1)), end="\n\n")

print("DKI 2")
predictions_dki2 = dki2_arima_model.predict(start=testDKI2ARIMA.index[0], end=testDKI2ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI2ARIMA["no2_diff"], predictions_dki2))
print("MSE:", mean_squared_error(testDKI2ARIMA["no2_diff"], predictions_dki2))
print("RMSE:", math.sqrt(mean_squared_error(testDKI2ARIMA["no2_diff"], predictions_dki2)), end="\n\n")

print("DKI 3")
predictions_dki3 = dki3_arima_model.predict(start=testDKI3ARIMA.index[0], end=testDKI3ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI3ARIMA["no2_diff"], predictions_dki3))
print("MSE:", mean_squared_error(testDKI3ARIMA["no2_diff"], predictions_dki3))
print("RMSE:", math.sqrt(mean_squared_error(testDKI3ARIMA["no2_diff"], predictions_dki3)), end="\n\n")

print("DKI 4")
predictions_dki4 = dki4_arima_model.predict(start=testDKI4ARIMA.index[0], end=testDKI4ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI4ARIMA["no2_diff"], predictions_dki4))
print("MSE:", mean_squared_error(testDKI4ARIMA["no2_diff"], predictions_dki4))
print("RMSE:", math.sqrt(mean_squared_error(testDKI4ARIMA["no2_diff"], predictions_dki4)), end="\n\n")

print("DKI 5")
predictions_dki5 = dki5_arima_model.predict(start=testDKI5ARIMA.index[0], end=testDKI5ARIMA.index[-1])
print("MAE:", mean_absolute_error(testDKI5ARIMA["no2_diff"], predictions_dki5))
print("MSE:", mean_squared_error(testDKI5ARIMA["no2_diff"], predictions_dki5))
print("RMSE:", math.sqrt(mean_squared_error(testDKI5ARIMA["no2_diff"], predictions_dki5)), end="\n\n")

"""## LSTM

### Buat fungsi untuk memprediksi model
"""

def model_forecast(model_path, series, window_size, batch_size, train_size):
  model = tf.keras.models.load_model(model_path)
  split_size = int(len(series) * train_size)
  ds = tf.data.Dataset.from_tensor_slices(series)
  ds = ds.window(window_size, shift=1, drop_remainder=True)
  ds = ds.flat_map(lambda w: w.batch(window_size))
  ds = ds.batch(batch_size, drop_remainder=True).prefetch(1)
  forecast = model.predict(ds)
  forecast = forecast[split_size - 7:-1, 0, 0]
  return forecast

"""### Eksekusi dan jalankan perhitungan metrik evaluasi"""

print("DKI 1")
prediction_dki1_lstm = model_forecast('/content/dki1_lstm.h5',
                                      dki1NO2TI_boxCoxNorm['no2_diff'].values,
                                      7, 25, 0.8)
test = np.squeeze(testDKI1LSTM['no2_diff'][:prediction_dki1_lstm.shape[0]])
print("MAE:", mean_absolute_error(test, prediction_dki1_lstm))
print("MSE:", mean_squared_error(test, prediction_dki1_lstm))
print("RMSE:", math.sqrt(mean_squared_error(test, prediction_dki1_lstm)), end="\n\n")

print("DKI 2")
prediction_dki2_lstm = model_forecast('/content/dki2_lstm.h5',
                                      dki2NO2TI_boxCoxNorm['no2_diff'].values,
                                      7, 25, 0.8)
test = np.squeeze(testDKI2LSTM['no2_diff'][:prediction_dki2_lstm.shape[0]])
print("MAE:", mean_absolute_error(test, prediction_dki2_lstm))
print("MSE:", mean_squared_error(test, prediction_dki2_lstm))
print("RMSE:", math.sqrt(mean_squared_error(test, prediction_dki2_lstm)), end="\n\n")

print("DKI 3")
prediction_dki3_lstm = model_forecast('/content/dki3_lstm.h5',
                                      dki3NO2TI_boxCoxNorm['no2_diff'].values,
                                      7, 25, 0.8)
test = np.squeeze(testDKI3LSTM['no2_diff'][:prediction_dki3_lstm.shape[0]])
print("MAE:", mean_absolute_error(test, prediction_dki3_lstm))
print("MSE:", mean_squared_error(test, prediction_dki3_lstm))
print("RMSE:", math.sqrt(mean_squared_error(test, prediction_dki3_lstm)), end="\n\n")

print("DKI 4")
prediction_dki4_lstm = model_forecast('/content/dki4_lstm.h5',
                                      dki4NO2TI_boxCoxNorm['no2_diff'].values,
                                      7, 25, 0.8)
test = np.squeeze(testDKI4LSTM['no2_diff'][:prediction_dki4_lstm.shape[0]])
print("MAE:", mean_absolute_error(test, prediction_dki4_lstm))
print("MSE:", mean_squared_error(test, prediction_dki4_lstm))
print("RMSE:", math.sqrt(mean_squared_error(test, prediction_dki4_lstm)), end="\n\n")

print("DKI 5")
prediction_dki5_lstm = model_forecast('/content/dki5_lstm.h5',
                                      dki5NO2TI_boxCoxNorm['no2_diff'].values,
                                      7, 25, 0.8)
test = np.squeeze(testDKI5LSTM['no2_diff'][:prediction_dki5_lstm.shape[0]])
print("MAE:", mean_absolute_error(test, prediction_dki5_lstm))
print("MSE:", mean_squared_error(test, prediction_dki5_lstm))
print("RMSE:", math.sqrt(mean_squared_error(test, prediction_dki5_lstm)), end="\n\n")

"""## Kesimpulan

Berdasarkan hasil dari perhitungan metrik untuk model ARIMA dan LSTM dapat dilihat dari tabel berikut

<table>
<thead>
  <tr>
    <th>Model</th>
    <th>Metrik<sup>*</sup></th>
    <th>DKI1</th>
    <th>DKI2</th>
    <th>DKI3</th>
    <th>DKI4</th>
    <th>DKI5</th>
  </tr>
</thead>
<tbody>
<tr>
    <td rowspan="3">ARIMA (4, 0 ,5)</td>
    <td>MAE</td>
    <td>1.139</td>
    <td>0.484</td>
    <td>0.478</td>
    <td>0.342</td>
    <td>0.409</td>
  </tr>
  <tr>
    <td>MSE</td>
    <td>2.674</td>
    <td>0.437</td>
    <td>0.492</td>
    <td>0.279</td>
    <td>0.336</td>
  </tr>
  <tr>
    <td>RMSE</td>
    <td>1.635</td>
    <td>0.661</td>
    <td>0.701</td>
    <td>0.528</td>
    <td>0.58</td>
  </tr>
  <tr>
    <td rowspan="3">ARIMA (5, 0, 5)</td>
    <td>MAE</td>
    <td>1.136</td>
    <td>0.484</td>
    <td>0.478</td>
    <td>0.342</td>
    <td>0.409</td>
  </tr>
  <tr>
    <td>MSE</td>
    <td>2.672</td>
    <td>0.437</td>
    <td>0.492</td>
    <td>0.279</td>
    <td>0.336</td>
  </tr>
  <tr>
    <td>RMSE</td>
    <td>1.635</td>
    <td>0.661</td>
    <td>0.701</td>
    <td>0.528</td>
    <td>0.58</td>
  </tr>
  <tr>
    <td rowspan="3">LSTM</td>
    <td>MAE</td>
    <td>1.046</td>
    <td>0.418</td>
    <td>0.421</td>
    <td>0.296</td>
    <td>0.374</td>
  </tr>
  <tr>
    <td>MSE</td>
    <td>2.132</td>
    <td>0.335</td>
    <td>0.358</td>
    <td>0.186</td>
    <td>0.275</td>
  </tr>
  <tr>
    <td>RMSE</td>
    <td>1.46</td>
    <td>0.579</td>
    <td>0.599</td>
    <td>0.432</td>
    <td>0.524</td>
  </tr>
</tbody>
</table>

<sup>*) Semakin kecil semakin baik</sup>

Berdasarkan tabel berikut dapat disimpulkan bahwa model LSTM memberikan hasil yang lebih baik dibandingkan menggunakan model ARIMA dimana hasil **MAE 10.32%, MSE 22.05% dan RMSE 12.45%** lebih baik di model LSTM dibandingkan dengan ARIMA.
"""